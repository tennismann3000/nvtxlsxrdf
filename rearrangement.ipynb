{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "import time\n",
    "import rdflib\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal, RDF\n",
    "from rdflib.namespace import NamespaceManager\n",
    "import datetime\n",
    "import urllib\n",
    "pd.options.display.max_colwidth = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvt_master = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "wgs84_pos = Namespace(\"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "edm = Namespace(\"http://www.europeana.eu/schemas/edm/\")\n",
    "dc = Namespace(\"http://purl.org/dc/elements/1.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "nvt = Namespace(\"http://lod.iti-germany.de/resource/\")\n",
    "nvto = Namespace(\"http://lod.iti-germany.de/schema/nvto/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "context = Namespace(\"http://lod.iti-germany.de/contexts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(Graph):    \n",
    "    nsm = NamespaceManager(Graph())\n",
    "    nsm.bind(\"nvto\", \"http://lod.iti-germany.de/schema/nvto/\")\n",
    "    nsm.bind(\"nvt\", \"http://lod.iti-germany.de/resource/\")\n",
    "    nsm.bind(\"owl\", \"http://www.w3.org/2002/07/owl#\")\n",
    "    nsm.bind(\"rdf\", \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    nsm.bind(\"rdfs\", \"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "    nsm.bind(\"wgs84_pos\", \"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "    nsm.bind(\"edm\", \"http://www.europeana.eu/schemas/edm/\")\n",
    "    nsm.bind(\"dc\", \"http://purl.org/dc/elements/1.1/\")\n",
    "    nsm.bind(\"dcterms\", \"http://purl.org/dc/terms/\")\n",
    "    nsm.bind(\"foaf\", \"http://xmlns.com/foaf/0.1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bindbind(graph):\n",
    "    graph.bind(\"nvto\", \"http://lod.iti-germany.de/schema/nvto/\")\n",
    "    graph.bind(\"nvt\", \"http://lod.iti-germany.de/resource/\")\n",
    "    graph.bind(\"owl\", \"http://www.w3.org/2002/07/owl#\")\n",
    "    graph.bind(\"rdf\", \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    graph.bind(\"rdfs\", \"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "    graph.bind(\"wgs84_pos\", \"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "    graph.bind(\"edm\", \"http://www.europeana.eu/schemas/edm/\")\n",
    "    graph.bind(\"dc\", \"http://purl.org/dc/elements/1.1/\")\n",
    "    graph.bind(\"dcterms\", \"http://purl.org/dc/terms/\")\n",
    "    graph.bind(\"skos\", \"http://www.w3.org/2004/02/skos/core#\")\n",
    "    graph.bind(\"foaf\", \"http://xmlns.com/foaf/0.1/\")\n",
    "    graph.bind(\"context\", \"http://lod.iti-germany.de/contexts/\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pr_graph = G(identifier=\"http://lod.iti-germany.de/contexts/productions\")\n",
    "#ev_graph = G(identifier=\"http://lod.iti-germany.de/contexts/events\")\n",
    "#vid_graph = G(identifier=\"http://lod.iti-germany.de/contexts/videos\")\n",
    "#text_graph = G(identifier=\"http://lod.iti-germany.de/contexts/texts\")\n",
    "#img_graph = G(identifier=\"http://lod.iti-germany.de/contexts/images\")\n",
    "#aud_graph = G(identifier=\"http://lod.iti-germany.de/contexts/audio\")\n",
    "#person_graph = G(identifier=\"http://lod.iti-germany.de/contexts/persons\")\n",
    "#group_graph = G(identifier=\"http://lod.iti-germany.de/contexts/groups\")\n",
    "#loc_graph = G(identifier=\"http://lod.iti-germany.de/contexts/locations\")\n",
    "#city_graph = G(identifier=\"http://lod.iti-germany.de/contexts/cities\")\n",
    "#country_graph = G(identifier=\"http://lod.iti-germany.de/contexts/countries\")\n",
    "#col_graph = G(identifier=\"http://lod.iti-germany.de/contexts/collections\")\n",
    "#series_graph = G(identifier=\"http://lGod.iti-germany.de/contexts/series\")\n",
    "#concept_graph = G(identifier=\"http://lod.iti-germany.de/contexts/concepts\")\n",
    "#graph_list = [pr_graph, ev_graph, vid_graph, text_graph, img_graph, aud_graph, person_graph, group_graph, loc_graph, city_graph, country_graph, col_graph, series_graph, concept_graph]\n",
    "#[n for n in pr_graph.namespaces()]\n",
    "#[n for n in pr_graph.nsm.namespaces()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvt_ds = rdflib.Dataset()\n",
    "nvt_ds = bindbind(nvt_ds)\n",
    "pr_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/productions\")\n",
    "ev_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/events\")\n",
    "vid_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/videos\")\n",
    "text_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/texts\")\n",
    "img_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/images\")\n",
    "aud_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/audio\")\n",
    "person_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/persons\")\n",
    "group_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/groups\")\n",
    "loc_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/locations\")\n",
    "city_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/cities\")\n",
    "country_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/countries\")\n",
    "col_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/collections\")\n",
    "series_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/series\")\n",
    "concept_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/concepts\")\n",
    "graph_list = [pr_graph, ev_graph, vid_graph, text_graph, img_graph, aud_graph, person_graph, group_graph, loc_graph, city_graph, country_graph, col_graph, series_graph, concept_graph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sheet():\n",
    "## name: Name des Reiters\n",
    "## head: Indikator, wo im df Tabellenüberschriften zu finden sind (0 = Inhalte Zeile 1, 1 = Inhalte Zeile 2, x = Index unverändert)\n",
    "## df: DataFrame pro Sheet\n",
    "## tdf: Kopie von df, mit über head definierter Indexanpassung\n",
    "## tdf_empty_transposed: DataFrame, der nur aus Überschriften (ohne Spaltenachsennamen) besteht, zur Konvertierung nach Excel, inklusive Transponierung\n",
    "    def __init__(self, name, head, df):\n",
    "        self.name = name\n",
    "        self.head = head\n",
    "        self.df = df\n",
    "        self.tdf = df.copy()\n",
    "        self.column_names = None\n",
    "        self.tdf_empty_transposed = None\n",
    "        if self.head != \"x\":\n",
    "            self.tdf.columns = self.tdf.iloc[self.head]\n",
    "            self.tdf.columns.name = None\n",
    "        else:\n",
    "            pass\n",
    "        if isinstance(self.tdf, pd.DataFrame):\n",
    "            self.column_names = self.tdf.columns.tolist()\n",
    "            self.tdf_empty_transposed = self.tdf[0:0].transpose(copy=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Column():\n",
    "    def __init__(self, name):\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zur Erzeungung von Sheet Instanzen mit Name und Spaltenkopfreferenz als Liste und mit dict Referenz\n",
    "## column_headers: Liste von 'echten' Spaltenüberschriften, 0, 1, für erste, zweite Zeile, x=Standard\n",
    "## col_ref dict um nicht mit Zahlen, sondern Namen zu arbeiten\n",
    "sheet_list = []\n",
    "col_ref = {}\n",
    "column_headers = [0, 0, 0, 0, 0, 0, 1, \"x\", \"x\", \"x\", \"x\", \"x\", \"x\"]\n",
    "for idx, i in enumerate([sheet for sheet in nvt_master.keys()][2:15]):\n",
    "    sheet_list.append(Sheet(name = i, head = column_headers[idx], df = nvt_master[i]))\n",
    "    col_ref[i] = sheet_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Mapping.xlsx', engine='xlsxwriter')\n",
    "for i in sheet_list:\n",
    "    i.tdf_empty_transposed.to_excel(writer, header=False, sheet_name=i.name)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_columns(df, col1, col2, result=None):\n",
    "    ## noch ein bisschen sauberer wäre gut, zeilenumbruch nach beschreibung vllt und personennamen in richtiger schreibweise\n",
    "    \n",
    "    if result == \"zeitraum\":\n",
    "        col3 = \"Zeitraum\"\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"timespan_\" + df[\"ID\"] + \"_\" + df[col1].apply(str).str[:4] + \"_\" + df[col2].apply(str).str[:4]\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"timespan_\" + df[\"ID\"] + \"_\" + df[col1].apply(str).str[:4]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \"timespan_\" + df[\"ID\"] + \"_\" + df[col2].apply(str).str[:4]\n",
    "        return df\n",
    "    \n",
    "    elif result == \"season\":\n",
    "        col3 = \"Spielzeit\"\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"season_\" + df[\"ID\"] + \"_\" + df[col1].apply(str).str[:4] + \"_\" + df[col2].apply(str).str[:4]\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"season_\" + df[\"ID\"] + \"_\" + df[col1].apply(str).str[:4]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \"season_\" + df[\"ID\"] + \"_\" + df[col2].apply(str).str[:4]\n",
    "        return df\n",
    "    \n",
    "    elif result == \"description\":\n",
    "        col3 = \"Beschreibung_Quelle\"\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"Beschreibung: \" + df[col1] + \" Quelle: \" + df[col2]\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"Beschreibung: \" + df[col1]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \" Quelle: \" + df[col2]\n",
    "        return df\n",
    "    \n",
    "    elif result == \"texts\":\n",
    "        col3 = \"Texte_Autoren\"\n",
    "        df[col2] = peoplereplace(df[col2])\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"Text(e): \" + df[col1] + \" Autor(en): \" + df[col2]\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"Text(e): \" + df[col1]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \"Autor(en): \" + df[col2]\n",
    "        return df\n",
    "    \n",
    "    elif result == \"condition\":\n",
    "        col3 = \"Zustand_Datum\"\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"Zustand: \" + df[col1] + \" Datum Zustandsaufnahme: \" + df[col2].apply(str)\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"Zustand: \" + df[col1]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \" Datum Zustandsaufnahme: \" + df[col2].apply(str)\n",
    "        return df\n",
    "    \n",
    "    elif result == \"institution\":\n",
    "        col3 = \"LOC_Institution\"\n",
    "        df.loc[df[col2].notna(), col3] = df[col1].str.replace(\"LOC_\", \"G_\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Wrong Keyword, nothing happened\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physicaldigital(df, col):\n",
    "    df.loc[df[col].notna(), \"Phys_ID\"] = \"phys_\" + df[col]\n",
    "    df.loc[df[col].notna(), \"Digi_ID\"] = \"digi_\" + df[col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globalcolumnrename(columns):\n",
    "    None\n",
    "##   columns = {'Identifier / geeinigter Name':'ID', ## renames columns for future reference\n",
    "##                                         'Produktionsname / Titel':'PR_Titel',\n",
    "##                                         'Quelle (Beschreibung)':'Q_Beschreibung',\n",
    "##                                         'Verwendete Texte':'Verwxendete_Texte',\n",
    "##                                         'Autor(en) der Texte':'Autoren_Texte',\n",
    "##                                         'Beteiligte Gruppen / Compagnies':'Beteiligte_Gruppen',\n",
    "##                                         'Sprecher*in':'SprecherIn',\n",
    "##                                         'Darsteller allgem.':'Darsteller',\n",
    "##                                         'Weitere Mitwirkende':'Mitwirkende',\n",
    "##                                         'Spielzeit / Laufzeit Start':'Spielzeit_Start',\n",
    "##                                         'Spielzeit / Laufzeit Ende':'Spielzeit_Ende'\n",
    "##                          } \n",
    "##   ## uvm, alle spaltennamen aus allen reitern holen und dann doppelte einträge entfernen \n",
    "##   ##(erst sicherstellen, dass nicht manche spaltennamen für verschiedene Bedeutungen genutzt werden)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peoplereplace(df):\n",
    "    ## temporary string beautifier for persons as literal values\n",
    "    df = df.str.replace(\"_\",\" \")\n",
    "    df = df.str.replace(\",\", \" \")\n",
    "    df = df.str.replace(\";\", \"; \")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refreplace(df):\n",
    "    ## string converter for URIs\n",
    "    df = df.str.lower()\n",
    "    df = df.str.replace(\"ä\", \"ae\")\n",
    "    df = df.str.replace(\"ö\",\"oe\")\n",
    "    df = df.str.replace(\"ü\",\"ue\")\n",
    "    df = df.str.replace(\"ß\",\"ss\")\n",
    "    df = df.str.replace(\"!?,\\.\", \"\")\n",
    "    df = df.str.replace(\"[^a-zA-Z0-9;]\", \"_\")\n",
    "    df = df.str.replace(\"-\", \"_\")\n",
    "    df = df.str.replace(\"__\", \"_\")\n",
    "    df = df.str.strip(\"_\")\n",
    "    df = df.str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supersplit(df):\n",
    "    ## for more convenient str splitting within the columns (expand=false), mainly for splitting all URIs\n",
    "    if df.any():\n",
    "        df = df.str.split(\";\", expand = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitreplace(df):\n",
    "    ## combines refreplace and supersplit in correct order for they are both always used for any columns containing URIs\n",
    "    df = df.apply(refreplace, axis=1)\n",
    "    df = df.apply(supersplit, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_reindex(df, index=None):\n",
    "    df = (df.sort_values(df.columns[index])\n",
    "          .reset_index(drop=True) ## resets index to be continouus            \n",
    "         )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniquify(df_columns):\n",
    "    seen = set()\n",
    "\n",
    "    for item in df_columns:\n",
    "        fudge = 0\n",
    "        newitem = item\n",
    "\n",
    "        while newitem in seen:\n",
    "            fudge += 1\n",
    "            newitem = \"{}.{}\".format(item, fudge)\n",
    "\n",
    "        yield newitem\n",
    "        seen.add(newitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnref(df, sheet=None):\n",
    "    ## erst Referenzliste mit Index, dann ->\n",
    "    ## Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None refreplace für I und R, split für R, erst split dann refreplace\n",
    "    for idx, i in enumerate(df.columns):\n",
    "        idxx = str(idx).zfill(2)\n",
    "        print(idxx, i)\n",
    "    if sheet == \"Produktionen\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(6, 26) or idx == 27 or idx in range(32, 36):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(2, 6) or idx == 26:\n",
    "                print([\"N\", idxx])\n",
    "            else:\n",
    "                print([\"L\", idxx, i])\n",
    "                \n",
    "    if sheet == \"Ereignisse\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx == 2 or idx in range(5, 31) or idx in range(35, 38) or idx == 39:\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(3, 5) or idx == 31:\n",
    "                print([\"N\", idxx])\n",
    "            else:\n",
    "                print([\"L\", idxx, i])\n",
    "                \n",
    "    if sheet == \"Videos\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 2:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range (7, 16) or idx in range (20, 44) or idx in range (47, 50) or idx == 60 or idx in range(68, 70):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx == 3 or idx in range (16, 18) or idx in range(45, 47) or idx in range (50, 52) or idx in range (56, 58) or idx in range(61, 65) or idx == 67:\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "    \n",
    "    if sheet == \"Text\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 2:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(7, 16) or idx in range(22, 34) or idx == 38 or idx == 40 or idx == 52 or idx in range(59, 61):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx == 3 or idx in range(16, 18) or idx in range(20, 22) or idx in range(34, 38) or idx == 39 or idx in range(41, 50) or idx in range(53, 56) or idx in range(57, 59):\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "    \n",
    "    if sheet == \"Bild\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 2:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(8, 18) or idx in range(20, 22) or idx in range(24, 27) or idx == 38 or idx in range (45, 47):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(22, 24) or idx in range (27, 36) or idx in range(39, 42) or idx in range(43, 45):\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "    \n",
    "    if sheet == \"Audio\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 2:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(7, 16) or idx in range(20, 25) or idx in range(28, 31) or idx == 40 or idx in range(48, 50):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(16, 18) or idx in range(26, 28) or idx in range(31, 33) or idx in range(36, 38) or idx in range(41, 45) or idx in range(46, 48):\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "                \n",
    "    if sheet == \"Personen\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(9, 15):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(1, 4) or idx in range(6,8) or idx == 15:\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "                \n",
    "    if sheet == \"Gruppen\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(5, 13):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(1, 3) or idx == 14:\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "                \n",
    "    if sheet == \"Locations\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0 or idx == 1:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(7, 10) or idx in range(12, 16) or idx == 17:\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(2, 4) or idx == 6 or idx in range(10, 12) or idx == 16:\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "    \n",
    "    if sheet == \"Städte\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(1, 4) or idx in range(5, 7):\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"R\", idxx, i])\n",
    "    \n",
    "    if sheet == \"Länder\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(1, 6):\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"R\", idxx, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uri_list(column2, predicate, column=\"ID\"):\n",
    "    if isinstance(row[column], list):\n",
    "        idid = row[column][0] ## weil id immer einzigartig ist\n",
    "        if isinstance(row[column2], list):\n",
    "            for i in row[column2]:\n",
    "                graph.add((nvt[idid], predicate, nvt[str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_list(column2, predicate, column=\"ID\"):\n",
    "    if isinstance(row[column], list):\n",
    "        idid = row[column][0] ## weil id immer einzigartig ist\n",
    "        if isinstance(row[column2], list):\n",
    "            for i in row[column2]:\n",
    "                uri = URIRef(i.strip()) ## strip an dieser Stelle weil ichs nich in supersplit hinbekommen habe\n",
    "                graph.add((nvt[idid], predicate, uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lit_list(column2, predicate, column=\"ID\", language=None):\n",
    "    lang = None\n",
    "    if isinstance(row[column], list):\n",
    "        idid = row[column][0]\n",
    "        if isinstance(row[column2], str) or isinstance(row[column2], datetime.datetime):\n",
    "            graph.add((nvt[idid], predicate, Literal(row[column2])))\n",
    "            if language:\n",
    "                graph.add((nvt[idid], predicate, Literal(row[column2], lang=language)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uri_type(column, uri_type):\n",
    "    if isinstance(row[column], list):\n",
    "        for i in row[column]:\n",
    "            graph.add((nvt[i], rdf.type, uri_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnref(pr_clean, sheet=\"Produktionen\")\n",
    "# columnref(ev_clean, sheet=\"Ereignisse\")\n",
    "# columnref(vid_clean, sheet=\"Videos\")\n",
    "# columnref(text_clean, sheet=\"Text\")\n",
    "# columnref(img_clean, sheet=\"Bild\")\n",
    "# columnref(aud_clean, sheet=\"Audio\")\n",
    "# columnref(person_clean, sheet=\"Personen\")\n",
    "# columnref(group_clean, sheet=\"Gruppen\")\n",
    "# columnref(loc_clean, sheet=\"Locations\")\n",
    "# columnref(city_clean, sheet=\"Städte\")\n",
    "# columnref(country_clean, sheet=\"Länder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_clean = nvt_master[\"Produktionen\"]\n",
    "pr_clean.columns = pr_clean.iloc[0]\n",
    "\n",
    "pr_clean = (pr_clean[pr_clean['Identifier / geeinigter Name'].str.contains('PR', na=False)] ## drops all rows that don't start with 'PR' or are NaN\n",
    "            .drop(pr_clean[pr_clean['Identifier / geeinigter Name'].str.contains('PR_Internationaler_Workshop_zur_Biomechanik_GITIS Moskau_Januar_1993', na=False)].index) \n",
    "            .rename(columns={'Identifier / geeinigter Name':'ID', ## renames columns for future reference\n",
    "                              'Produktionsname / Titel':'PR_Titel',\n",
    "                              'Quelle (Beschreibung)':'Q_Beschreibung',\n",
    "                              'Verwendete Texte':'Verwendete_Texte',\n",
    "                              'Autor(en) der Texte':'Autoren_Texte',\n",
    "                              'Beteiligte Gruppen / Compagnies':'Beteiligte_Gruppen',\n",
    "                              'Sprecher*in':'SprecherIn',\n",
    "                              'Darsteller allgem.':'Darsteller',\n",
    "                              'Weitere Mitwirkende':'Mitwirkende',\n",
    "                              'Spielzeit / Laufzeit Start':'Spielzeit_Start',\n",
    "                              'Spielzeit / Laufzeit Ende':'Spielzeit_Ende'\n",
    "                           }\n",
    "                   )\n",
    "           )\n",
    "pr_clean = merge_columns(pr_clean, \"Spielzeit_Start\", \"Spielzeit_Ende\", result = \"season\") ## in Zukunft vllt nur Keyword, wenn Tabellentitel angepasst sind\n",
    "pr_clean = merge_columns(pr_clean, \"Verwendete_Texte\", \"Autoren_Texte\", result = \"texts\") ## in Zukunft müssten die Autoren mit der Personentabelle abgeglichen werden, am besten trotzdem noch als literal\n",
    "pr_clean = merge_columns(pr_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "\n",
    "pr_clean.iloc[:, [0]] = splitreplace(pr_clean.iloc[:, [0]])\n",
    "pr_clean.iloc[:, 6:28] = splitreplace(pr_clean.iloc[:, 6:28])\n",
    "pr_clean.iloc[:, 32:36] = splitreplace(pr_clean.iloc[:, 32:36])\n",
    "\n",
    "pr_clean = sort_reindex(pr_clean, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr_clean.to_excel(\"output_pr_clean.xlsx\")\n",
    "# pr_clean.loc[0,:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_clean = nvt_master[\"Ereignisse\"]\n",
    "ev_clean.columns = ev_clean.iloc[0]\n",
    "\n",
    "ev_clean = (ev_clean[ev_clean['Identifier / geeinigter Name'].str.contains('EV', na=False)]\n",
    "            .drop(ev_clean[ev_clean['Identifier / geeinigter Name'].str.contains('EV_Internationaler_Workshop_zur_Biomechanik_GITIS Moskau_Januar_1993_001', na=False)].index) ## drops example line\n",
    "            .rename(columns={'Identifier / geeinigter Name':'ID', ## renames columns for future reference\n",
    "                             'Ereignisname / Ereignistitel':'EV_Titel',\n",
    "                             'Quelle (Beschreibung)':'Q_Beschreibung',\n",
    "                             'Gehört zu Produktion':'Gehört_PR',\n",
    "                             'Erwähnung von':'Erwähnung_von',\n",
    "                             'Bezug auf / Über / zentraler Gegenstand (Subject)':'Subject',\n",
    "                             'Teilereignis von':'Teilereignis_von',\n",
    "                             'Beteiligte Gruppen / Compagnies':'Beteiligte_Gruppen',\n",
    "                             'Sprecher*in':'SprecherIn',\n",
    "                             'Darsteller allgem.':'Darsteller',\n",
    "                             'Lehrer  / Workshopleiter':'Lehrer',\n",
    "                             'Weitere Mitwirkende':'Mitwirkende',\n",
    "                             'Zeitpunkt (Datum)':'Zeitpunkt',\n",
    "                             'Zeitraum Start':'Zeitraum_Start',\n",
    "                             'Zeitraum Ende':'Zeitraum_Ende'\n",
    "                           }\n",
    "                   )\n",
    "           )\n",
    "ev_clean = merge_columns(ev_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "ev_clean = merge_columns(ev_clean, \"Zeitraum_Start\", \"Zeitraum_Ende\", result = \"zeitraum\")\n",
    "\n",
    "ev_clean.iloc[:, 5:31] = splitreplace(ev_clean.iloc[:, 5:31])\n",
    "ev_clean.iloc[:, [0, 2, 35, 36, 37, 39]] = splitreplace(ev_clean.iloc[:, [0, 2, 35, 36, 37, 39]])\n",
    "\n",
    "ev_clean = sort_reindex(ev_clean, index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_clean = nvt_master[\"Objekte VIDEOS\"]\n",
    "vid_clean.columns = vid_clean.iloc[0]\n",
    "vid_clean = (vid_clean[vid_clean['Projekt ID'].str.contains('vid', na=False)]\n",
    "             .rename(columns={'Projekt ID':'ID',\n",
    "                              'andere IDs':'andere_ID',\n",
    "                              'Unterobjekt von':'Unterobjekt_von',\n",
    "                              'Serie / Abfolge':'Serie',\n",
    "                              'Sammlung (Projekt / DB)':'Sammlung',\n",
    "                              'Gleicher Inhalt':'Gleicher_Inhalt',\n",
    "                              'Abgebildete Produktionen':'Abgebildete_Produktionen',\n",
    "                              'Erwähnte Produktionen':'Erwähnte_Produktionen',\n",
    "                              'Annotation/Beschreibung':'Beschreibung',\n",
    "                              'Quelle (Annotation)':'Q_Beschreibung',\n",
    "                              'Abgebildete Ereignisse':'Abgebildete_Ereignisse',\n",
    "                              'Erwähnte Ereignisse':'Erwähnte_Ereignisse',\n",
    "                              'Kamera / Aufzeichner':'Kamera_Aufzeichner',\n",
    "                              'Sichtbare Entitäten':'Sichtbare_Entitäten',\n",
    "                              'Hörbare Entitäten':'Hörbare_Entitäten',\n",
    "                              '(Irgendwie) Erwähnte Entitäten':'Erwähnte_Entitäten',\n",
    "                              'Erwähnte Gruppen / Compagnies':'Erwähnte_Gruppen',\n",
    "                              'Beitragsregie / Fernsehregie':'Beitragsregie_Fernsehregie',\n",
    "                              'Sprecher*in':'SprecherIn',\n",
    "                              'Darsteller allgem.':'Darsteller',\n",
    "                              'Weitere Mitwirkende':'Mitwirkende',\n",
    "                              'Sprache des Objekts':'Sprache_Objekt',\n",
    "                              'Länge gesamtes Band':'Länge_Band',\n",
    "                              'Zustand Objekt':'Zustand_Phys',\n",
    "                              'Objekt identisch mit':'Objekt_identisch_mit',\n",
    "                              'Zustand Digitalisat':'Zustand_Digi'                              \n",
    "                             }\n",
    "                    ) \n",
    "            )\n",
    "\n",
    "\n",
    "vid_clean = merge_columns(vid_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "vid_clean = merge_columns(vid_clean, \"Zustand_Phys\", \"Datum Zustandsaufnahme\", result = \"condition\")\n",
    "vid_clean = physicaldigital(vid_clean, \"ID\")\n",
    "\n",
    "vid_clean.iloc[:, [2, 68, 69]] = splitreplace(vid_clean.iloc[:, [2, 68, 69]])\n",
    "vid_clean.iloc[:, 7:16] = splitreplace(vid_clean.iloc[:, 7:16])\n",
    "vid_clean.iloc[:, 20:44] = splitreplace(vid_clean.iloc[:, 20:44])\n",
    "vid_clean.iloc[:, 47:50] = splitreplace(vid_clean.iloc[:, 47:50])\n",
    "\n",
    "vid_clean = sort_reindex(vid_clean, index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean = nvt_master[\"Objekte TEXT\"]\n",
    "text_clean.columns = text_clean.iloc[0]\n",
    "\n",
    "text_clean = (text_clean[text_clean['Projekt ID'].str.contains('txt', na=False)]\n",
    "              .rename(columns={'Projekt ID':'ID',\n",
    "                               'andere IDs':'andere_ID',\n",
    "                               'Unterobjekt von':'Unterobjekt_von',\n",
    "                               'Bildserie':'Serie',\n",
    "                               'Sammlung (Projekt / DB)':'Sammlung',\n",
    "                               'Gleiche Inhalte':'Gleicher_Inhalt',\n",
    "                               'Abgebildete Produktionen':'Abgebildete_Produktionen',\n",
    "                               'Erwähnte Produktionen':'Erwähnte_Produktionen',\n",
    "                               'Abgebildete Ereignisse':'Abgebildete_Ereignisse',\n",
    "                               'Erwähnte Ereignisse':'Erwähnte_Ereignisse',\n",
    "                               'Annotation/Beschreibung':'Beschreibung',\n",
    "                               'Quelle (Annotation)':'Q_Beschreibung',\n",
    "                               'Herausgeberschaft (Institution / Verlag)':'Herausgeberschaft',\n",
    "                               'Herausgeber*in (Person)':'HerausgeberIn',\n",
    "                               'Autor*in':'AutorIn',\n",
    "                               'Übersetzer*in':'ÜbersetzerIn',\n",
    "                               'Layout/Satz':'Layout',\n",
    "                               'Grafik/künstl. Gestaltung':'Grafik_Gestaltung',\n",
    "                               'Weitere Mitwirkende':'Mitwirkende',\n",
    "                               'Erwähnung Personen':'Erwähnung_Personen',\n",
    "                               'Erwähnte Gruppen':'Erwähnung_Gruppen',\n",
    "                               'Sichtbare Personen':'Sichtbare_Personen',\n",
    "                               'Sichtbare Gruppen':'Sichtbare_Gruppen',\n",
    "                               'Erstausgabe (der vorliegenden Sprache)':'Erstausgabe_Sprache',\n",
    "                               'Erscheinungsstadt ':'Erscheinungsstadt',\n",
    "                               'Anzahl Exemplare':'Anzahl_Exemplare',\n",
    "                               'Format (Dimensionen)':'Phys_Format',\n",
    "                               'Zustand Objekt':'Zustand_Phys',\n",
    "                               'Datum Zustandsaufnahme':'Datum_Zustandsaufnahme',\n",
    "                               'Objekt identisch mit':'Objekt_identisch_mit',\n",
    "                               'Zustand Digitalisat':'Zustand_Digi'\n",
    "                              }\n",
    "                     )    \n",
    "             )\n",
    "\n",
    "text_clean = merge_columns(text_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "text_clean = merge_columns(text_clean, \"Zustand_Phys\", \"Datum_Zustandsaufnahme\", result = \"condition\")\n",
    "text_clean = physicaldigital(text_clean, \"ID\")\n",
    "\n",
    "text_clean.iloc[:, [2, 38, 40, 52, 59, 60]] = splitreplace(text_clean.iloc[:, [2, 38, 40, 52, 59, 60]])\n",
    "text_clean.iloc[:, 7:16] = splitreplace(text_clean.iloc[:, 7:16])\n",
    "text_clean.iloc[:, 22:34] = splitreplace(text_clean.iloc[:, 22:34])\n",
    "\n",
    "text_clean = sort_reindex(text_clean, index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_clean = nvt_master[\"Objekte BILD\"]\n",
    "img_clean.columns = img_clean.iloc[0]\n",
    "\n",
    "img_clean = (img_clean[img_clean['Projekt ID'].str.contains('img', na=False)]\n",
    "             .sort_values(img_clean.columns[2])\n",
    "             .rename(columns={'Projekt ID':'ID',\n",
    "                              'andere IDs':'andere_ID',\n",
    "                              'Unterobjekt von':'Unterobjekt_von',\n",
    "                              'Bildserie':'Serie',\n",
    "                              'Sammlung (Projekt / DB)':'Sammlung',\n",
    "                              'Gleiches Motive':'Gleicher_Inhalt',\n",
    "                              'Abgebildete Produktionen':'Abgebildete_Produktionen',\n",
    "                              'Erwähnte Produktionen':'Erwähnte_Produktionen',\n",
    "                              'Abgebildete Ereignisse':'Abgebildete_Ereignisse',\n",
    "                              'Erwähnte Ereignisse':'Erwähnte_Ereignisse',\n",
    "                              'Motivbeschreibung':'Beschreibung',\n",
    "                              'Quelle (Beschreibung)':'Q_Beschreibung',\n",
    "                              'abgebildete Entitäten':'abgebildete_Entitäten',\n",
    "                              'Fotograf*in':'FotografIn',\n",
    "                              'Aufnahmedatum/Entstehungsdatum':'Aufnahmedatum',\n",
    "                              'Beschriftung + Markierungen (vorn)':'Beschriftung_Vorn',\n",
    "                              'Beschriftung + Markierungen (hinten)':'Beschriftung_Hinten',\n",
    "                              'Bildtyp/ Träger':'Träger',\n",
    "                              'Farbe (nach AAT)':'Farbe',\n",
    "                              'Zustand Objekt':'Zustand_Phys',\n",
    "                              'Datum Zustandsaufnahme':'Datum_Zustandsaufnahme',\n",
    "                              'Objekt identisch mit':'Objekt_identisch_mit',\n",
    "                              'Zustand Digitalisat':'Zustand_Digi'\n",
    "                             }\n",
    "                    )    \n",
    "            )\n",
    "\n",
    "img_clean = merge_columns(img_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "img_clean = merge_columns(img_clean, \"Zustand_Phys\", \"Datum_Zustandsaufnahme\", result = \"condition\")\n",
    "img_clean = physicaldigital(img_clean, \"ID\")\n",
    "\n",
    "img_clean.iloc[:, [2, 20, 21, 24, 25, 26, 38, 45, 46]] = splitreplace(img_clean.iloc[:, [2, 20, 21, 24, 25, 26, 38, 45, 46]])\n",
    "img_clean.iloc[:, 8:17] = splitreplace(img_clean.iloc[:, 8:17])\n",
    "\n",
    "img_clean = sort_reindex(img_clean, index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_clean = nvt_master[\"Objekte AUDIO\"]\n",
    "aud_clean.columns = aud_clean.iloc[0]\n",
    "\n",
    "aud_clean = (aud_clean[aud_clean['Projekt ID'].str.contains('aud', na=False)]\n",
    "             .rename(columns={'Projekt ID':'ID',\n",
    "                              'andere IDs':'andere_ID',\n",
    "                              'Unterobjekt von':'Unterobjekt_von',\n",
    "                              'Sammlung (Projekt / DB)':'Sammlung',\n",
    "                              'Gleiche Aufnahme':'Gleicher_Inhalt',\n",
    "                              'Abgebildete Produktionen':'Abgebildete_Produktionen',\n",
    "                              'Erwähnte Produktionen':'Erwähnte_Produktionen',\n",
    "                              'Abgebildete Ereignisse':'Abgebildete_Ereignisse',\n",
    "                              'Erwähnte Ereignisse':'Erwähnte_Ereignisse',\n",
    "                              'Annotation/Beschreibung':'Beschreibung',\n",
    "                              'Quelle (Annotation)':'Q_Beschreibung',\n",
    "                              'Hörbare Entitäten':'Hörbare_Entitäten',\n",
    "                              '(Irgendwie) Erwähnte Entitäten':'Erwähnte_Entitäten',\n",
    "                              'Aufzeichner*in':'AufzeichnerIn',\n",
    "                              'Beitragsregie / Radioregie':'Beitragsregie',\n",
    "                              'Erwähnte Gruppen / Compagnies':'Erwähnte_Gruppen',\n",
    "                              'Sprache des Objekts':'Sprache',\n",
    "                              'Audioträger / Typ':'Träger',\n",
    "                              'Länge gesamtes Band':'Länge_Band',\n",
    "                              'Zustand Objekt':'Zustand_Phys',\n",
    "                              'Datum Zustandsaufnahme':'Datum_Zustandsaufnahme',\n",
    "                              'Objekt identisch mit':'Objekt_identisch_mit',\n",
    "                              'Zustand Digitalisat':'Zustand_Digi'\n",
    "                             }\n",
    "                    )           \n",
    "            )\n",
    "\n",
    "aud_clean = merge_columns(aud_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "aud_clean = merge_columns(aud_clean, \"Zustand_Phys\", \"Datum_Zustandsaufnahme\", result = \"condition\")\n",
    "aud_clean = physicaldigital(aud_clean, \"ID\")\n",
    "\n",
    "aud_clean.iloc[:, [2, 28, 29, 30, 40, 48, 49]] = splitreplace(aud_clean.iloc[:, [2, 28, 29, 30, 40, 48, 49]])\n",
    "aud_clean.iloc[:, 7:16] = splitreplace(aud_clean.iloc[:, 7:16])\n",
    "aud_clean.iloc[:, 20:25] = splitreplace(aud_clean.iloc[:, 20:25])\n",
    "\n",
    "aud_clean = sort_reindex(aud_clean, index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_clean = nvt_master[\"||_Personen\"]\n",
    "person_clean.columns = person_clean.iloc[1]\n",
    "\n",
    "person_clean = (person_clean[person_clean['Identifier / geeinigte Schreibweise'].str.contains(',', na=False)]\n",
    "                .drop(person_clean[person_clean['Identifier / geeinigte Schreibweise'].str.contains('Vorname Vatersname,Nachname', na=False)].index)\n",
    "                .rename(columns={\"Identifier / geeinigte Schreibweise\":\"ID\",\n",
    "                                \"Quelle (Beschreibung)\":\"Q_Beschreibung\"}\n",
    "                       )\n",
    "               )\n",
    "\n",
    "person_clean = merge_columns(person_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "\n",
    "person_clean.iloc[:, [0]] = splitreplace(person_clean.iloc[:, [0]])\n",
    "person_clean.iloc[:, 9:15] = person_clean.iloc[:, 9:15].apply(supersplit, axis=1) ## weil die inhalte weblinks sind kein str.replace\n",
    "\n",
    "person_clean = sort_reindex(person_clean, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_clean = nvt_master[\"||_Gruppen_Ensembles\"]\n",
    "\n",
    "group_clean = (group_clean[group_clean['Gruppe Identifier / geeinigte Schreibweise'].str.contains('G_', na=False)]\n",
    "                .rename(columns={\"Gruppe Identifier / geeinigte Schreibweise\":\"ID\",\n",
    "                                \"präferierter Name\":\"Name\",\n",
    "                                \"weitere Namen\":\"Namen\",\n",
    "                                \"Quelle Beschreibung\":\"Q_Beschreibung\",\n",
    "                                \"ist Vorgänger von\":\"Vorgänger_von\",\n",
    "                                \"ist Nachfolger von\":\"Nachfolger_von\",\n",
    "                                \"ist ansässig Stadt\":\"ansässig_Stadt\",\n",
    "                                \"ist ansässig Land\":\"ansässig_Land\",\n",
    "                                 \"ist ansässig Haus\":\"ansässig_Haus\",\n",
    "                                 \"WIKIDATA URI\":\"Wikidata\"\n",
    "                                }\n",
    "                       )\n",
    "               )\n",
    "\n",
    "group_clean = merge_columns(group_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "group_clean.iloc[:, [0, 5, 6, 7, 8, 9]] = splitreplace(group_clean.iloc[:, [0, 5, 6, 7, 8, 9]])\n",
    "group_clean.iloc[:, [10, 11, 12]] = group_clean.iloc[:, [10, 11, 12]].apply(supersplit, axis=1) ## weil die inhalte weblinks sind kein str.replace\n",
    "\n",
    "group_clean = sort_reindex(group_clean, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_clean = nvt_master[\"||_Veranstaltungsort\"]\n",
    "\n",
    "loc_clean = (loc_clean[loc_clean['PROJEKT'].str.contains('LOC_', na=False)]\n",
    "             .rename(columns={\"PROJEKT\":\"ID\",\n",
    "                              \"ist Institution\":\"ist_Institution\",\n",
    "                              \"präferierter Ortsname\":\"Ortsname\",\n",
    "                              \"weitere Ortsnamen\":\"weitere_Ortsnamen\",\n",
    "                              \"Quelle Beschreibung\":\"Q_Beschreibung\",\n",
    "                              \"Gehört Zu\":\"Gehört_Zu\",\n",
    "                              \"geo:LAT\":\"LAT\",\n",
    "                              \"geo:LONG\":\"LONG\",\n",
    "                              \"Wikipedia URI\":\"Wikipedia\",\n",
    "                              \"GND URI\":\"GND\",\n",
    "                              \"WIKIDATA URI\":\"WIKIDATA\",\n",
    "                              \"geonames URI\":\"geonames\"\n",
    "                             }\n",
    "                    )\n",
    "            )\n",
    "loc_clean = merge_columns(loc_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "loc_clean = merge_columns(loc_clean, \"ID\", \"ist_Institution\", result=\"institution\")\n",
    "loc_clean.iloc[:, [0, 7, 8, 9, 17]] = splitreplace(loc_clean.iloc[:, [0, 7, 8, 9, 17]])\n",
    "loc_clean.iloc[:, 12:16] = loc_clean.iloc[:, 12:16].apply(supersplit, axis=1)\n",
    "\n",
    "loc_clean = sort_reindex(loc_clean, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_clean = nvt_master[\"||_Städte\"]\n",
    "\n",
    "\n",
    "city_clean = (city_clean.rename(columns={\"Stadt Identifier / geeinigte Schreibweise\":\"ID\",\n",
    "                                         \"präferierter Stadtname\":\"präf_Stadtname\",\n",
    "                                         \"Stadtname DE\":\"Stadtname_DE\",\n",
    "                                         \"Stadtname EN\":\"Stadtname_EN\",\n",
    "                                         \"LAND (Ref)\":\"Land\",\n",
    "                                         \"geo:LAT\":\"LAT\",\n",
    "                                         \"geo:LONG\":\"LONG\",\n",
    "                                         \"geonames URI\":\"geonames\"\n",
    "                                        }\n",
    "                               )\n",
    "             )\n",
    "city_clean.iloc[:, [0, 4]] = splitreplace(city_clean.iloc[:, [0, 4]])\n",
    "city_clean.iloc[:, [7]] = city_clean.iloc[:, [7]].apply(supersplit, axis=1)\n",
    "\n",
    "city_clean = sort_reindex(city_clean, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_clean = nvt_master[\"||_Länder\"]\n",
    "\n",
    "country_clean = (country_clean.rename(columns={\"Länder Identifier / geeinigte Schreibweise\":\"ID\",\n",
    "                                               \"präferierter Ländername\":\"präf_Landname\",\n",
    "                                               \"Ländername DE\":\"Landname_DE\",\n",
    "                                               \"Ländername EN\":\"Landname_EN\",\n",
    "                                               \"geo:LAT\":\"LAT\",\n",
    "                                               \"geo:LONG\":\"LONG\",\n",
    "                                               \"geonames URI\":\"geonames\"\n",
    "                                              }\n",
    "                                     )\n",
    "                )\n",
    "country_clean.iloc[:, [0]] = splitreplace(country_clean.iloc[:, [0]])\n",
    "country_clean.iloc[:, [6]] = country_clean.iloc[:, [6]].apply(supersplit, axis=1)\n",
    "\n",
    "country_clean = sort_reindex(country_clean, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_clean = nvt_master[\"Sammlungen\"]\n",
    "\n",
    "col_clean = (col_clean[col_clean['PROJEKT'].str.contains('COL_', na=False)]\n",
    "             .drop(col_clean[col_clean['PROJEKT'].str.contains('COL_Identifier', na=False)].index)\n",
    "             .rename(columns={\"PROJEKT\":\"ID\",\n",
    "                              \"Sammlungsbeschreibung\":\"Beschreibung\",\n",
    "                              \"Quelle der Beschreibung\":\"Q_Beschreibung\"\n",
    "                             }\n",
    "                    )\n",
    "            )\n",
    "col_clean.iloc[:, [0]] = splitreplace(col_clean.iloc[:, [0]])\n",
    "col_clean = merge_columns(col_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "\n",
    "col_clean = sort_reindex(col_clean, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_clean = nvt_master[\"Serie\"]\n",
    "\n",
    "series_clean = (series_clean[series_clean['PROJEKT'].str.contains('SRS_', na=False)]\n",
    "                .drop(series_clean[series_clean['PROJEKT'].str.contains('SRS_Identifier', na=False)].index)\n",
    "                .rename(columns={\"PROJEKT\":\"ID\",\n",
    "                                 \"Serienbeschreibung\":\"Beschreibung\",\n",
    "                                 \"Quelle der Beschreibung\":\"Q_Beschreibung\"\n",
    "                                }\n",
    "                       )\n",
    "               )\n",
    "\n",
    "series_clean.iloc[:, [0]] = splitreplace(series_clean.iloc[:, [0]])\n",
    "series_clean = merge_columns(series_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "\n",
    "series_clean = sort_reindex(series_clean, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in pr_clean.iterrows():\n",
    "    \n",
    "    graph = pr_graph\n",
    "    ##id_id = str(row[\"ID\"][0])\n",
    "    \n",
    "    uri_type(\"ID\", nvto.PerformingArtsProduction)\n",
    "    \n",
    "    lit_list(\"PR_Titel\", dcterms.title)\n",
    "    lit_list(\"PR_Titel\", skos.prefLabel)\n",
    "    lit_list(\"Premierendatum\", nvto.hasFirstPerformanceDate)\n",
    "    lit_list(\"Premierendatum\", nvto.hasLastPerformanceDate)\n",
    "    \n",
    "    uri_list(\"Produktionstyp\", dcterms.type)\n",
    "    uri_list(\"Beteiligte_Gruppen\", dcterms.contributor)\n",
    "    uri_list(\"Konzept\", nvto.hasConceptOriginator)\n",
    "    uri_list(\"Textbearbeitung\", nvto.hasAdaptor)\n",
    "    uri_list(\"Übersetzung\", nvto.hasTranslator)\n",
    "    uri_list(\"Regie\", nvto.hasDirector)\n",
    "    uri_list(\"SprecherIn\", nvto.hasSpeaker)\n",
    "    uri_list(\"Choreographie\", nvto.hasChoreographer)\n",
    "    uri_list(\"Dramaturgie\", nvto.hasDramaturge)\n",
    "    uri_list(\"Bühnenbild\", nvto.hasSetDesigner)\n",
    "    uri_list(\"Kostümdesgin\", nvto.hasCostumedesigner)\n",
    "    uri_list(\"Figurenbau\", nvto.hasPuppetDesigner)\n",
    "    uri_list(\"Maskenbau\", nvto.hasMaskDesigner)\n",
    "    uri_list(\"Lichtdesign\", nvto.hasLightDesigner)\n",
    "    uri_list(\"Videodesign\", nvto.hasVideoDesigner)\n",
    "    uri_list(\"Schauspieler\", nvto.hasActor)\n",
    "    uri_list(\"Tänzer\", nvto.hasDancer)\n",
    "    uri_list(\"Darsteller\", nvto.hasPerformer)\n",
    "    uri_list(\"Musiker\", nvto.hasMusician)\n",
    "    uri_list(\"Komposition\", nvto.hasComposer)\n",
    "    uri_list(\"Mitwirkende\", dcterms.contributor)\n",
    "    uri_list(\"Veranstaltungsort\", nvto.happenedAtPlace)\n",
    "    uri_list(\"Stadt\", nvto.happenedAtPlace)\n",
    "    uri_list(\"Land\", nvto.happenedAtPlace)\n",
    "    uri_list(\"Spielzeit\", nvto.hasSeason)\n",
    "    uri_type(\"Spielzeit\", nvto.TimeSpan)\n",
    "    uri_type(\"Produktionstyp\", skos.Concept)\n",
    "    \n",
    "    lit_list(\"Spielzeit_Start\", nvto.beginsAtTime, \"Spielzeit\")\n",
    "    lit_list(\"Spielzeit_Ende\", nvto.endsAtTime, \"Spielzeit\")\n",
    "    \n",
    "    lit_list(\"Texte_Autoren\", dcterms.description)\n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in ev_clean.iterrows():\n",
    "    \n",
    "    graph = ev_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.Event)\n",
    "    \n",
    "    lit_list(\"EV_Titel\", skos.prefLabel)\n",
    "    \n",
    "    uri_list(\"Ereignisart\", dcterms.type)\n",
    "    uri_list(\"Gehört_PR\", dcterms.isPartOf)\n",
    "    uri_list(\"Erwähnung_von\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Subject\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Teilereignis_von\", dcterms.isPartOf)\n",
    "    uri_list(\"Beteiligte_Gruppen\", dcterms.contributor)\n",
    "    uri_list(\"Konzept\", nvto.hasConceptOriginator)\n",
    "    uri_list(\"Textbearbeitung\", nvto.hasAdaptor)\n",
    "    uri_list(\"Übersetzung\", nvto.hasTranslator)\n",
    "    uri_list(\"Regie\", nvto.hasDirector)\n",
    "    uri_list(\"SprecherIn\", nvto.hasSpeaker)\n",
    "    uri_list(\"Choreographie\", nvto.hasChoreographer)\n",
    "    uri_list(\"Dramaturgie\", nvto.hasDramaturge)\n",
    "    uri_list(\"Bühnenbild\", nvto.hasSetDesigner)\n",
    "    uri_list(\"Kostümdesgin\", nvto.hasCostumedesigner)\n",
    "    uri_list(\"Figurenbau\", nvto.hasPuppetDesigner)\n",
    "    uri_list(\"Maskenbau\", nvto.hasMaskDesigner)\n",
    "    uri_list(\"Lichtdesign\", nvto.hasLightDesigner)\n",
    "    uri_list(\"Videodesign\", nvto.hasVideoDesigner)\n",
    "    uri_list(\"Schauspieler\", nvto.hasActor)\n",
    "    uri_list(\"Tänzer\", nvto.hasDancer)\n",
    "    uri_list(\"Darsteller\", nvto.hasPerformer)\n",
    "    uri_list(\"Musiker\", nvto.hasMusician)\n",
    "    uri_list(\"Komposition\", nvto.hasComposer)\n",
    "    uri_list(\"Lehrer\", dcterms.mediator)\n",
    "    uri_list(\"Teilnehmer\", nvto.hasParticipant)\n",
    "    uri_list(\"Mitwirkende\", dcterms.contributor)\n",
    "    \n",
    "    lit_list(\"Zeitpunkt\", dcterms.date)\n",
    "    lit_list(\"Zeitraum_Start\", nvto.beginsAtTime, \"Zeitraum\")\n",
    "    lit_list(\"Zeitraum_Ende\", nvto.endsAtTime, \"Zeitraum\")\n",
    "    \n",
    "    uri_list(\"Veranstaltungsort\", nvto.happenedAtPlace)\n",
    "    uri_list(\"Stadt\", nvto.happenedAtPlace)\n",
    "    uri_list(\"Land\", nvto.happenedAtPlace)\n",
    "    \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.source)\n",
    "    \n",
    "    uri_list(\"Zeitraum\", nvto.hasSeason)\n",
    "    \n",
    "    uri_type(\"Zeitraum\", nvto.TimeSpan)\n",
    "    uri_type(\"Ereignisart\", skos.Concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in vid_clean.iterrows():\n",
    "    \n",
    "    graph = vid_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.InformationObject)\n",
    "    \n",
    "    uri_list(\"Phys_ID\", nvto.hasInformationCarrier)\n",
    "    uri_list(\"Digi_ID\", nvto.hasInformationCarrier)\n",
    "    uri_list(\"Digi_ID\", nvto.hasDigitalVersion, \"Phys_ID\")\n",
    "    \n",
    "    uri_type(\"Phys_ID\", nvto.PhysicalObject)\n",
    "    uri_type(\"Digi_ID\", nvto.DigitalObject)\n",
    "    \n",
    "    lit_list(\"andere_ID\", dcterms.identifier)\n",
    "    \n",
    "    uri_list(\"Archivalientyp\", dcterms.type)\n",
    "    uri_type(\"Archivalientyp\", skos.Concept)\n",
    "    uri_list(\"Unterobjekt_von\", dcterms.isPartOf)\n",
    "    uri_list(\"Serie\", dcterms.isPartOf)\n",
    "    uri_list(\"Sammlung\", dcterms.isPartOf)\n",
    "    uri_list(\"Gleicher_Inhalt\", nvto.hasContentMatch)\n",
    "    uri_list(\"Abgebildete_Produktionen\", nvto.containsAudioVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Produktionen\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Abgebildete_Ereignisse\", nvto.containsAudioVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Ereignisse\", nvto.containsReferenceTo)\n",
    "    \n",
    "    \n",
    "    lit_list(\"Titel\", skos.prefLabel)\n",
    "    lit_list(\"Titel\", dcterms.title)\n",
    "    lit_list(\"Untertitel\", nvto.hasSubtitle)\n",
    "    \n",
    "    uri_list(\"Kamera_Aufzeichner\", nvto.hasCinematographer)\n",
    "    uri_list(\"Sichtbare_Entitäten\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Hörbare_Entitäten\", nvto.containsAudibleReferenceTo)\n",
    "    uri_list(\"Erwähnte_Entitäten\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Erwähnte_Gruppen\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Autorenschaft\", nvto.hasAuthor)\n",
    "    uri_list(\"Beitragsregie_Fernsehregie\", nvto.hasDirector)\n",
    "    uri_list(\"SprecherIn\", nvto.hasSpeaker)\n",
    "    uri_list(\"Choreographie\", nvto.hasChoreographer)\n",
    "    uri_list(\"Dramaturgie\", nvto.hasDramaturge)\n",
    "    uri_list(\"Bühnenbild\", nvto.hasSetDesigner)\n",
    "    uri_list(\"Maske\", nvto.hasMaskDesigner)\n",
    "    uri_list(\"Lichtdesign\", nvto.hasLightDesigner)\n",
    "    uri_list(\"Videodesign\", nvto.hasVideoDesigner)\n",
    "    uri_list(\"Schauspieler\", nvto.hasActor)\n",
    "    uri_list(\"Tänzer\", nvto.hasDancer)\n",
    "    uri_list(\"Darsteller\", nvto.hasPerformer)\n",
    "    uri_list(\"Musiker\", nvto.hasMusician)\n",
    "    uri_list(\"Komposition\", nvto.hasComposer)\n",
    "    uri_list(\"Mitwirkende\", dcterms.contributor)\n",
    "    uri_list(\"Editor\", nvto.hasVideoEditor)\n",
    "    uri_list(\"Ton\", nvto.hasRecordist)\n",
    "    \n",
    "    lit_list(\"Sprache_Objekt\", dcterms.language)\n",
    "    lit_list(\"Aufnahmedatum\", dcterms.created)\n",
    "    \n",
    "    uri_list(\"Entstehungsort\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Stadt\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Land\", nvto.originatedAtPlace)\n",
    "    \n",
    "    lit_list(\"Rechteinhaber\", dcterms.rightsHolder)\n",
    "    \n",
    "    lit_list(\"Träger\", dcterms.medium, \"Phys_ID\")\n",
    "    lit_list(\"Länge_Band\", dcterms.extent, \"Phys_ID\")\n",
    "    lit_list(\"Herkunft\", dcterms.provenance, \"Phys_ID\")\n",
    "    lit_list(\"Zustand_Datum\", nvto.hasCondition, \"Phys_ID\")\n",
    "    lit_list(\"Copyright\", dcterms.rights, \"Phys_ID\")\n",
    "    \n",
    "    uri_list(\"Objekt_identisch_mit\", nvto.hasContentMatch)\n",
    "    \n",
    "    lit_list(\"Zustand_Digi\", nvto.hasCondition, \"Digi_ID\")\n",
    "    lit_list(\"Länge\", dcterms.extent, \"Digi_ID\")\n",
    "    lit_list(\"Dateiformat\", nvto.hasDigitalFormat, \"Digi_ID\")\n",
    "    \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in text_clean.iterrows():\n",
    "    \n",
    "    graph = text_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.InformationObject)\n",
    "    \n",
    "    uri_list(\"Phys_ID\", nvto.hasInformationCarrier)\n",
    "    uri_list(\"Digi_ID\", nvto.hasInformationCarrier)\n",
    "    \n",
    "    uri_type(\"Phys_ID\", nvto.PhysicalObject)\n",
    "    uri_type(\"Digi_ID\", nvto.DigitalObject)\n",
    "    \n",
    "    uri_list(\"Digi_ID\", nvto.hasDigitalVersion, \"Phys_ID\")\n",
    "    \n",
    "    \n",
    "    lit_list(\"andere_ID\", dcterms.identifier)\n",
    "    \n",
    "    uri_list(\"Archivalientyp\", dcterms.type)\n",
    "    uri_type(\"Archivalientyp\", skos.Concept)\n",
    "    \n",
    "    uri_list(\"Unterobjekt_von\", dcterms.isPartOf)\n",
    "    uri_list(\"Serie\", dcterms.isPartOf)\n",
    "    uri_list(\"Sammlung\", dcterms.isPartOf)\n",
    "    uri_list(\"Gleicher_Inhalt\", nvto.hasContentMatch)\n",
    "    uri_list(\"Abgebildete_Produktionen\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Produktionen\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Abgebildete_Ereignisse\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Ereignisse\", nvto.containsReferenceTo)\n",
    "    \n",
    "    lit_list(\"Titel\", skos.prefLabel)\n",
    "    lit_list(\"Titel\", dcterms.title)\n",
    "    lit_list(\"Untertitel\", nvto.hasSubtitle)\n",
    "    lit_list(\"Inhaltsverzeichnis\", dcterms.tableOfContents)\n",
    "    lit_list(\"Herausgeberschaft\", dcterms.publisher)\n",
    "    \n",
    "    uri_list(\"HerausgeberIn\", dcterms.publisher)\n",
    "    uri_list(\"AutorIn\", nvto.hasAuthor)\n",
    "    uri_list(\"ÜbersetzerIn\", nvto.hasTranslator)\n",
    "    uri_list(\"Layout\", nvto.hasLayouter)\n",
    "    uri_list(\"Grafik_Gestaltung\", nvto.hasIllustrator)\n",
    "    uri_list(\"Redaktion\", nvto.hasEditor)\n",
    "    uri_list(\"Fotografie\", nvto.hasPhotographer)    \n",
    "    uri_list(\"Mitwirkende\", dcterms.contributor)\n",
    "    uri_list(\"Erwähnung_Personen\", nvto.containsTextualReferenceTo)\n",
    "    uri_list(\"Erwähnung_Gruppen\", nvto.containsTextualReferenceTo)\n",
    "    uri_list(\"Sichtbare_Personen\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Sichtbare_Gruppen\", nvto.containsVisualReferenceTo)\n",
    "    \n",
    "    lit_list(\"Verlag\", dcterms.publisher)\n",
    "    lit_list(\"Originalausgabe\", nvto.hasFirstEdition)\n",
    "    lit_list(\"Erstausgabe_Sprache\", nvto.hasFirstLocalizedEdition)\n",
    "    lit_list(\"Erscheinungsdatum\", dcterms.issued)\n",
    "    \n",
    "    uri_list(\"Erscheinungsstadt\", nvto.hasPublishingPlace)\n",
    "    \n",
    "    lit_list(\"Sprache\", dcterms.language)\n",
    "    \n",
    "    uri_list(\"Land\", nvto.hasPublishingPlace)\n",
    "    \n",
    "    lit_list(\"Klassifikation\", dcterms.type)\n",
    "    lit_list(\"Textquelle\", dcterms.source)\n",
    "    lit_list(\"ISBN\", nvto.hasIsbn)\n",
    "    \n",
    "    lit_list(\"Träger\", dcterms.medium, \"Phys_ID\")\n",
    "    lit_list(\"Herkunft\", dcterms.provenance, \"Phys_ID\")\n",
    "    lit_list(\"Umfang\", dcterms.extent, \"Phys_ID\")\n",
    "    lit_list(\"Phys_Format\", dcterms[\"format\"], \"Phys_ID\")\n",
    "    lit_list(\"Zustand_Datum\", nvto.hasCondition, \"Phys_ID\")\n",
    "    lit_list(\"Copyright\", dcterms.rights, \"Phys_ID\")\n",
    "\n",
    "    uri_list(\"Objekt_identisch_mit\", nvto.hasContentMatch)\n",
    "    \n",
    "    lit_list(\"Zustand_Digi\", nvto.hasCondition, \"Digi_ID\")\n",
    "    lit_list(\"Dateiformat\", nvto.hasDigitalFormat, \"Digi_ID\")\n",
    "    \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in img_clean.iterrows():\n",
    "    \n",
    "    graph = img_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.InformationObject)\n",
    "    \n",
    "    uri_list(\"Phys_ID\", nvto.hasInformationCarrier)\n",
    "    uri_list(\"Digi_ID\", nvto.hasInformationCarrier)\n",
    "    \n",
    "    uri_type(\"Phys_ID\", nvto.PhysicalObject)\n",
    "    uri_type(\"Digi_ID\", nvto.DigitalObject)\n",
    "    \n",
    "    uri_list(\"Digi_ID\", nvto.hasDigitalVersion, \"Phys_ID\")\n",
    "    \n",
    "    \n",
    "    lit_list(\"andere_ID\", dcterms.identifier)\n",
    "    \n",
    "    uri_list(\"Archivalientyp\", dcterms.type)\n",
    "    uri_type(\"Archivalientyp\", skos.Concept)\n",
    "    \n",
    "    uri_list(\"Unterobjekt_von\", dcterms.isPartOf)\n",
    "    uri_list(\"Serie\", dcterms.isPartOf)\n",
    "    uri_list(\"Sammlung\", dcterms.isPartOf)\n",
    "    uri_list(\"Gleicher_Inhalt\", nvto.hasContentMatch)\n",
    "    \n",
    "    uri_list(\"Abgebildete_Produktionen\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Produktionen\", nvto.containsTextualReferenceTo)\n",
    "    uri_list(\"Abgebildete_Ereignisse\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Ereignisse\", nvto.containsTextualReferenceTo)\n",
    "    \n",
    "    lit_list(\"Bezeichner\", skos.prefLabel)\n",
    "    lit_list(\"Bezeichner\", dcterms.title)\n",
    "    \n",
    "    uri_list(\"abgebildete_Entitäten\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"FotografIn\", nvto.hasPhotographer)    \n",
    "    uri_list(\"Fotostudio\", nvto.hasPhotoStudio)\n",
    "    \n",
    "    lit_list(\"Aufnahmedatum\", dcterms.created)\n",
    "    \n",
    "    uri_list(\"Aufnahmeort\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Aufnahmestadt\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Aufnahmeland\", nvto.originatedAtPlace)\n",
    "    \n",
    "    lit_list(\"Beschriftung_Vorn\", nvto.hasLabelingFront, \"Phys_ID\")\n",
    "    lit_list(\"Beschriftung_Hinten\", nvto.hasLabelingBack, \"Phys_ID\")\n",
    "    lit_list(\"Objektbeschreibung\", dcterms.description, \"Phys_ID\")\n",
    "    lit_list(\"Herkunft\", dcterms.provenance, \"Phys_ID\")\n",
    "    \n",
    "    lit_list(\"Rechteinhaber\", dcterms.rightsHolder)\n",
    "        \n",
    "    lit_list(\"Träger\", dcterms.medium, \"Phys_ID\")\n",
    "    \n",
    "    lit_list(\"Farbe\", dcterms[\"format\"])\n",
    "    \n",
    "    lit_list(\"Dimensionen\", nvto.hasDimensions, \"Phys_ID\")\n",
    "    \n",
    "    uri_list(\"Objekt_identisch_mit\", nvto.hasContentMatch)\n",
    "    \n",
    "    lit_list(\"Zustand_Digi\", nvto.hasCondition, \"Digi_ID\")\n",
    "    lit_list(\"Dateiformat\", nvto.hasDigitalFormat, \"Digi_ID\")\n",
    "    \n",
    "    lit_list(\"Copyright\", dcterms.rights, \"Phys_ID\")\n",
    "    \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)\n",
    "    \n",
    "    lit_list(\"Zustand_Datum\", nvto.hasCondition, \"Phys_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in aud_clean.iterrows():\n",
    "    \n",
    "    graph = aud_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.InformationObject)\n",
    "    \n",
    "    uri_list(\"Phys_ID\", nvto.hasInformationCarrier)\n",
    "    uri_list(\"Digi_ID\", nvto.hasInformationCarrier)\n",
    "    \n",
    "    uri_type(\"Phys_ID\", nvto.PhysicalObject)\n",
    "    uri_type(\"Digi_ID\", nvto.DigitalObject)\n",
    "    \n",
    "    uri_list(\"Digi_ID\", nvto.hasDigitalVersion, \"Phys_ID\")\n",
    "    \n",
    "    \n",
    "    lit_list(\"andere_ID\", dcterms.identifier)\n",
    "    \n",
    "    uri_list(\"Archivalientyp\", dcterms.type)\n",
    "    uri_type(\"Archivalientyp\", skos.Concept)\n",
    "    \n",
    "    uri_list(\"Unterobjekt_von\", dcterms.isPartOf)\n",
    "    uri_list(\"Serie\", dcterms.isPartOf)\n",
    "    uri_list(\"Sammlung\", dcterms.isPartOf)\n",
    "    uri_list(\"Gleicher_Inhalt\", nvto.hasContentMatch)\n",
    "    uri_list(\"Abgebildete_Produktionen\", nvto.containsAudibleReferenceTo)\n",
    "    uri_list(\"Erwähnte_Produktionen\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Abgebildete_Ereignisse\", nvto.containsAudibleReferenceTo)\n",
    "    uri_list(\"Erwähnte_Ereignisse\", nvto.containsReferenceTo)\n",
    "    \n",
    "    lit_list(\"Titel\", skos.prefLabel)\n",
    "    lit_list(\"Titel\", dcterms.title)\n",
    "    lit_list(\"Untertitel\", nvto.hasSubtitle)\n",
    "    \n",
    "    uri_list(\"Hörbare_Entitäten\", nvto.containsAudibleReferenceTo)\n",
    "    uri_list(\"Erwähnte_Entitäten\", nvto.containsReferenceTo)\n",
    "    uri_list(\"AufzeichnerIn\", nvto.hasRecordist)\n",
    "    uri_list(\"Beitragsregie\", nvto.hasDirector)\n",
    "    uri_list(\"Erwähnte_Gruppen\", nvto.containsReferenceTo)\n",
    "    \n",
    "    lit_list(\"Aufnahmedatum\", dcterms.created)\n",
    "    lit_list(\"Sprache\", dcterms.language)\n",
    "    \n",
    "    uri_list(\"Entstehungsort\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Stadt\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Land\", nvto.originatedAtPlace)\n",
    "    \n",
    "    lit_list(\"Träger\", dcterms.medium, \"Phys_ID\")\n",
    "    lit_list(\"Länge_Band\", dcterms.extent, \"Phys_ID\")\n",
    "    lit_list(\"Herkunft\", dcterms.provenance, \"Phys_ID\")\n",
    "    \n",
    "    lit_list(\"Rechteinhaber\", dcterms.rightsHolder)\n",
    "    \n",
    "    \n",
    "    uri_list(\"Objekt_identisch_mit\", nvto.hasContentMatch)\n",
    "    \n",
    "    lit_list(\"Zustand_Digi\", nvto.hasCondition, \"Digi_ID\")\n",
    "    lit_list(\"Dateiformat\", nvto.hasDigitalFormat, \"Digi_ID\")\n",
    "    \n",
    "    lit_list(\"Copyright\", dcterms.rights, \"Phys_ID\")\n",
    "    \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)\n",
    "    \n",
    "    lit_list(\"Zustand_Datum\", nvto.hasCondition, \"Phys_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in person_clean.iterrows():\n",
    "    \n",
    "    graph = person_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.Agent)\n",
    "    \n",
    "    lit_list(\"Vollname\", skos.prefLabel)\n",
    "    lit_list(\"Vollname\", foaf.name)\n",
    "    lit_list(\"Vorname\", foaf.firstName)\n",
    "    lit_list(\"Nachname\", foaf.familyName)\n",
    "    lit_list(\"Geboren\", nvto.hasDateOfBirth)\n",
    "    lit_list(\"Gestorben\", nvto.hasDateOfDeath)\n",
    "    \n",
    "    url_list(\"VIAF\", owl.sameAs)\n",
    "    url_list(\"GND\", owl.sameAs)\n",
    "    url_list(\"Wikidata\", owl.sameAs)\n",
    "    url_list(\"Website\", owl.sameAs)\n",
    "    url_list(\"Websites\", owl.sameAs)\n",
    "    url_list(\"dbpedia\", owl.sameAs)\n",
    "        \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in group_clean.iterrows():\n",
    "    \n",
    "    graph = group_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.PerformingArtsGroup)\n",
    "    \n",
    "    lit_list(\"Name\", skos.prefLabel)\n",
    "    lit_list(\"Namen\", skos.altLabel)\n",
    "    \n",
    "    uri_list(\"Vorgänger_von\", nvto.hasPredecessor)\n",
    "    uri_list(\"Nachfolger_von\", nvto.hasSuccessor)\n",
    "    \n",
    "    uri_list(\"ansässig_Stadt\", nvto.hasRelatedPlace)\n",
    "    uri_list(\"ansässig_Land\", nvto.hasRelatedPlace)\n",
    "    uri_list(\"ansässig_Haus\", nvto.hasResidence)\n",
    "    \n",
    "    url_list(\"Website\", foaf.homepage)\n",
    "    url_list(\"Wikidata\", owl.sameAs)\n",
    "    url_list(\"GND URI\", owl.sameAs)\n",
    "        \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in loc_clean.iterrows():\n",
    "    \n",
    "    graph = loc_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.PerformingArtsLocation)\n",
    "    \n",
    "    lit_list(\"Ortsname\", skos.prefLabel)\n",
    "    lit_list(\"weitere_Ortsnamen\", skos.altLabel)\n",
    "    lit_list(\"Adresse\", nvto.hasAddress)\n",
    "    \n",
    "    uri_list(\"Gehört zu\", nvto.isResidenceOf)    \n",
    "    uri_list(\"STADT\", dcterms.isPartOf)\n",
    "    uri_list(\"LAND\", dcterms.isPartOf)\n",
    "    \n",
    "    lit_list(\"LAT\", wgs84_pos.lat)\n",
    "    lit_list(\"LONG\", wgs84_pos.long)\n",
    "    \n",
    "    url_list(\"Wikipedia\", owl.sameAs)\n",
    "    url_list(\"GND\", owl.sameAs)\n",
    "    url_list(\"WIKIDATA\", owl.sameAs)\n",
    "    url_list(\"geonames\", owl.sameAs)\n",
    "        \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)\n",
    "    \n",
    "    lit_list(\"LOC_Institution\", nvto.isResidenceOf)\n",
    "    uri_type(\"LOC_Institution\", nvto.PerformingArtsGroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in city_clean.iterrows():\n",
    "    \n",
    "    graph = city_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.City)\n",
    "    \n",
    "    lit_list(\"präf_Stadtname\", skos.prefLabel)\n",
    "    lit_list(\"Stadtname_DE\", skos.altLabel, language=\"de\")\n",
    "    lit_list(\"Stadtname_EN\", skos.altLabel, language=\"en\")\n",
    "    \n",
    "    uri_list(\"Land\", dcterms.isPartOf)\n",
    "    \n",
    "    lit_list(\"LAT\", wgs84_pos.lat)\n",
    "    lit_list(\"LONG\", wgs84_pos.long)\n",
    "    \n",
    "    url_list(\"geonames\", owl.sameAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in country_clean.iterrows():\n",
    "    \n",
    "    graph = country_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.Country)\n",
    "    \n",
    "    lit_list(\"präf_Landname\", skos.prefLabel)\n",
    "    lit_list(\"Landname_DE\", skos.altLabel, language=\"de\")\n",
    "    lit_list(\"Landname_EN\", skos.altLabel, language=\"en\")\n",
    "        \n",
    "    lit_list(\"LAT\", wgs84_pos.lat)\n",
    "    lit_list(\"LONG\", wgs84_pos.long)\n",
    "    \n",
    "    url_list(\"geonames\", owl.sameAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in col_clean.iterrows():\n",
    "    \n",
    "    graph = col_graph    \n",
    "    \n",
    "    uri_type(\"ID\", nvto.Collection)\n",
    "    \n",
    "    lit_list(\"Sammlungstitel\", skos.prefLabel)\n",
    "    lit_list(\"Sammlungstitel\", dcterms.title)\n",
    "        \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in series_clean.iterrows():\n",
    "    \n",
    "    graph = series_graph    \n",
    "    \n",
    "    uri_type(\"ID\", nvto.Series)\n",
    "    \n",
    "    lit_list(\"Serientitel\", skos.prefLabel)\n",
    "    lit_list(\"Serientitel\", dcterms.title)\n",
    "        \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with open('./ttl/nvt_productions.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(pr_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_events.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(ev_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_videos.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(vid_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_text.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(text_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_img.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(img_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_aud.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(aud_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_person.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(person_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_group.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(group_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_location.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(loc_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_city.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(city_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_country.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(country_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_collection.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(col_graph.serialize(format=\"turtle\"))\n",
    "## with open('./ttl/nvt_series.ttl', 'wb') as f_ttl:\n",
    "##     f_ttl.write(series_graph.serialize(format=\"turtle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nvt_ds.trig', 'wb') as f_trig:\n",
    "    f_trig.write(nvt_ds.serialize(format=\"trig\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
