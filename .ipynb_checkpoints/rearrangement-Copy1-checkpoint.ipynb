{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "import time\n",
    "import rdflib\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal, RDF\n",
    "from rdflib.namespace import NamespaceManager\n",
    "import datetime\n",
    "import urllib\n",
    "pd.options.display.max_colwidth = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "wgs84_pos = Namespace(\"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "edm = Namespace(\"http://www.europeana.eu/schemas/edm/\")\n",
    "dc = Namespace(\"http://purl.org/dc/elements/1.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "nvt = Namespace(\"http://lod.iti-germany.de/resource/\")\n",
    "nvto = Namespace(\"http://lod.iti-germany.de/schema/nvto/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "context = Namespace(\"http://lod.iti-germany.de/contexts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(Graph):    \n",
    "    nsm = NamespaceManager(Graph())\n",
    "    nsm.bind(\"nvto\", \"http://lod.iti-germany.de/schema/nvto/\")\n",
    "    nsm.bind(\"nvt\", \"http://lod.iti-germany.de/resource/\")\n",
    "    nsm.bind(\"owl\", \"http://www.w3.org/2002/07/owl#\")\n",
    "    nsm.bind(\"rdf\", \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    nsm.bind(\"rdfs\", \"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "    nsm.bind(\"wgs84_pos\", \"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "    nsm.bind(\"edm\", \"http://www.europeana.eu/schemas/edm/\")\n",
    "    nsm.bind(\"dc\", \"http://purl.org/dc/elements/1.1/\")\n",
    "    nsm.bind(\"dcterms\", \"http://purl.org/dc/terms/\")\n",
    "    nsm.bind(\"foaf\", \"http://xmlns.com/foaf/0.1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bindbind(graph):\n",
    "    graph.bind(\"nvto\", \"http://lod.iti-germany.de/schema/nvto/\")\n",
    "    graph.bind(\"nvt\", \"http://lod.iti-germany.de/resource/\")\n",
    "    graph.bind(\"owl\", \"http://www.w3.org/2002/07/owl#\")\n",
    "    graph.bind(\"rdf\", \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    graph.bind(\"rdfs\", \"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "    graph.bind(\"wgs84_pos\", \"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "    graph.bind(\"edm\", \"http://www.europeana.eu/schemas/edm/\")\n",
    "    graph.bind(\"dc\", \"http://purl.org/dc/elements/1.1/\")\n",
    "    graph.bind(\"dcterms\", \"http://purl.org/dc/terms/\")\n",
    "    graph.bind(\"skos\", \"http://www.w3.org/2004/02/skos/core#\")\n",
    "    graph.bind(\"foaf\", \"http://xmlns.com/foaf/0.1/\")\n",
    "    graph.bind(\"context\", \"http://lod.iti-germany.de/contexts/\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pr_graph = G(identifier=\"http://lod.iti-germany.de/contexts/productions\")\n",
    "#ev_graph = G(identifier=\"http://lod.iti-germany.de/contexts/events\")\n",
    "#vid_graph = G(identifier=\"http://lod.iti-germany.de/contexts/videos\")\n",
    "#text_graph = G(identifier=\"http://lod.iti-germany.de/contexts/texts\")\n",
    "#img_graph = G(identifier=\"http://lod.iti-germany.de/contexts/images\")\n",
    "#aud_graph = G(identifier=\"http://lod.iti-germany.de/contexts/audio\")\n",
    "#person_graph = G(identifier=\"http://lod.iti-germany.de/contexts/persons\")\n",
    "#group_graph = G(identifier=\"http://lod.iti-germany.de/contexts/groups\")\n",
    "#loc_graph = G(identifier=\"http://lod.iti-germany.de/contexts/locations\")\n",
    "#city_graph = G(identifier=\"http://lod.iti-germany.de/contexts/cities\")\n",
    "#country_graph = G(identifier=\"http://lod.iti-germany.de/contexts/countries\")\n",
    "#col_graph = G(identifier=\"http://lod.iti-germany.de/contexts/collections\")\n",
    "#series_graph = G(identifier=\"http://lGod.iti-germany.de/contexts/series\")\n",
    "#concept_graph = G(identifier=\"http://lod.iti-germany.de/contexts/concepts\")\n",
    "#graph_list = [pr_graph, ev_graph, vid_graph, text_graph, img_graph, aud_graph, person_graph, group_graph, loc_graph, city_graph, country_graph, col_graph, series_graph, concept_graph]\n",
    "#[n for n in pr_graph.namespaces()]\n",
    "#[n for n in pr_graph.nsm.namespaces()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvt_ds = rdflib.Dataset()\n",
    "nvt_ds = bindbind(nvt_ds)\n",
    "pr_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/productions\")\n",
    "ev_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/events\")\n",
    "vid_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/videos\")\n",
    "text_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/texts\")\n",
    "img_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/images\")\n",
    "aud_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/audio\")\n",
    "person_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/persons\")\n",
    "group_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/groups\")\n",
    "loc_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/locations\")\n",
    "city_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/cities\")\n",
    "country_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/countries\")\n",
    "col_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/collections\")\n",
    "series_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/series\")\n",
    "concept_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/concepts\")\n",
    "graph_list = [pr_graph, ev_graph, vid_graph, text_graph, img_graph, aud_graph, person_graph, group_graph, loc_graph, city_graph, country_graph, col_graph, series_graph, concept_graph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_columns(df, col1, col2, result=None):\n",
    "    ## noch ein bisschen sauberer wäre gut, zeilenumbruch nach beschreibung vllt und personennamen in richtiger schreibweise\n",
    "    \n",
    "    if result == \"zeitraum\":\n",
    "        col3 = \"Zeitraum\"\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"timespan_\" + df[\"ID\"] + \"_\" + df[col1].apply(str).str[:4] + \"_\" + df[col2].apply(str).str[:4]\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"timespan_\" + df[\"ID\"] + \"_\" + df[col1].apply(str).str[:4]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \"timespan_\" + df[\"ID\"] + \"_\" + df[col2].apply(str).str[:4]\n",
    "        return df\n",
    "    \n",
    "    elif result == \"season\":\n",
    "        col3 = \"Spielzeit\"\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"season_\" + df[\"ID\"] + \"_\" + df[col1].apply(str).str[:4] + \"_\" + df[col2].apply(str).str[:4]\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"season_\" + df[\"ID\"] + \"_\" + df[col1].apply(str).str[:4]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \"season_\" + df[\"ID\"] + \"_\" + df[col2].apply(str).str[:4]\n",
    "        return df\n",
    "    \n",
    "    elif result == \"description\":\n",
    "        col3 = \"Beschreibung_Quelle\"\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"Beschreibung: \" + df[col1] + \" Quelle: \" + df[col2]\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"Beschreibung: \" + df[col1]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \" Quelle: \" + df[col2]\n",
    "        return df\n",
    "    \n",
    "    elif result == \"texts\":\n",
    "        col3 = \"Texte_Autoren\"\n",
    "        df[col2] = peoplereplace(df[col2])\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"Text(e): \" + df[col1] + \" Autor(en): \" + df[col2]\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"Text(e): \" + df[col1]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \"Autor(en): \" + df[col2]\n",
    "        return df\n",
    "    \n",
    "    elif result == \"condition\":\n",
    "        col3 = \"Zustand_Datum\"\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"Zustand: \" + df[col1] + \" Datum Zustandsaufnahme: \" + df[col2].apply(str)\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"Zustand: \" + df[col1]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \" Datum Zustandsaufnahme: \" + df[col2].apply(str)\n",
    "        return df\n",
    "    \n",
    "    elif result == \"institution\":\n",
    "        col3 = \"LOC_Institution\"\n",
    "        df.loc[df[col2].notna(), col3] = df[col1].str.replace(\"LOC_\", \"G_\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Wrong Keyword, nothing happened\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physicaldigital(df, col):\n",
    "    df.loc[df[col].notna(), \"Phys_ID\"] = \"phys_\" + df[col]\n",
    "    df.loc[df[col].notna(), \"Digi_ID\"] = \"digi_\" + df[col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globalcolumnrename(columns):\n",
    "    None\n",
    "##   columns = {'Identifier / geeinigter Name':'ID', ## renames columns for future reference\n",
    "##                                         'Produktionsname / Titel':'PR_Titel',\n",
    "##                                         'Quelle (Beschreibung)':'Q_Beschreibung',\n",
    "##                                         'Verwendete Texte':'Verwxendete_Texte',\n",
    "##                                         'Autor(en) der Texte':'Autoren_Texte',\n",
    "##                                         'Beteiligte Gruppen / Compagnies':'Beteiligte_Gruppen',\n",
    "##                                         'Sprecher*in':'SprecherIn',\n",
    "##                                         'Darsteller allgem.':'Darsteller',\n",
    "##                                         'Weitere Mitwirkende':'Mitwirkende',\n",
    "##                                         'Spielzeit / Laufzeit Start':'Spielzeit_Start',\n",
    "##                                         'Spielzeit / Laufzeit Ende':'Spielzeit_Ende'\n",
    "##                          } \n",
    "##   ## uvm, alle spaltennamen aus allen reitern holen und dann doppelte einträge entfernen \n",
    "##   ##(erst sicherstellen, dass nicht manche spaltennamen für verschiedene Bedeutungen genutzt werden)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peoplereplace(df):\n",
    "    ## temporary string beautifier for persons as literal values\n",
    "    df = df.str.replace(\"_\",\" \")\n",
    "    df = df.str.replace(\",\", \" \")\n",
    "    df = df.str.replace(\";\", \"; \")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refreplace(df):\n",
    "    ## string converter for URIs\n",
    "    df = df.str.lower()\n",
    "    df = df.str.replace(\"ä\", \"ae\")\n",
    "    df = df.str.replace(\"ö\",\"oe\")\n",
    "    df = df.str.replace(\"ü\",\"ue\")\n",
    "    df = df.str.replace(\"ß\",\"ss\")\n",
    "    df = df.str.replace(\"!?,\\.\", \"\")\n",
    "    df = df.str.replace(\"[^a-zA-Z0-9;]\", \"_\")\n",
    "    df = df.str.replace(\"-\", \"_\")\n",
    "    df = df.str.replace(\"__\", \"_\")\n",
    "    df = df.str.strip(\"_\")\n",
    "    df = df.str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supersplit(df):\n",
    "    ## for more convenient str splitting within the columns (expand=false), mainly for splitting all URIs\n",
    "    if df.any():\n",
    "        df = df.str.split(\";\", expand = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitreplace(df):\n",
    "    ## combines refreplace and supersplit in correct order for they are both always used for any columns containing URIs\n",
    "    df = df.apply(refreplace, axis=1)\n",
    "    df = df.apply(supersplit, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnref(df, sheet=None):\n",
    "    ## erst Referenzliste mit Index, dann ->\n",
    "    ## Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None refreplace für I und R, split für R, erst split dann refreplace\n",
    "    for idx, i in enumerate(df.columns):\n",
    "        idxx = str(idx).zfill(2)\n",
    "        print(idxx, i)\n",
    "    if sheet == \"Produktionen\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(6, 27) or idx in range(31, 35):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(2, 6):\n",
    "                print([\"N\", idxx])\n",
    "            else:\n",
    "                print([\"L\", idxx, i])\n",
    "                \n",
    "    if sheet == \"Ereignisse\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx == 2 or idx in range(5, 31) or idx in range(35, 38) or idx == 39:\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(3, 5) or idx == 31:\n",
    "                print([\"N\", idxx])\n",
    "            else:\n",
    "                print([\"L\", idxx, i])\n",
    "                \n",
    "    if sheet == \"Videos\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 2:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range (7, 16) or idx in range (20, 44) or idx in range (47, 50) or idx == 60 or idx in range(68, 70):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx == 3 or idx in range (16, 18) or idx in range(45, 47) or idx in range (50, 52) or idx in range (56, 58) or idx in range(61, 65) or idx == 67:\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "    \n",
    "    if sheet == \"Text\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 2:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(7, 16) or idx in range(22, 34) or idx == 38 or idx == 40 or idx == 52 or idx in range(59, 61):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx == 3 or idx in range(16, 18) or idx in range(20, 22) or idx in range(34, 38) or idx == 39 or idx in range(41, 50) or idx in range(53, 56) or idx in range(57, 59):\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "    \n",
    "    if sheet == \"Bild\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 2:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(8, 18) or idx in range(20, 22) or idx in range(24, 27) or idx == 38 or idx in range (45, 47):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(22, 24) or idx in range (27, 36) or idx in range(39, 42) or idx in range(43, 45):\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "    \n",
    "    if sheet == \"Audio\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 2:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(7, 16) or idx in range(20, 25) or idx in range(28, 31) or idx == 40 or idx in range(48, 50):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(16, 18) or idx in range(26, 28) or idx in range(31, 33) or idx in range(36, 38) or idx in range(41, 45) or idx in range(46, 48):\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "                \n",
    "    if sheet == \"Personen\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(9, 15):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(1, 4) or idx in range(6,8) or idx == 15:\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "                \n",
    "    if sheet == \"Gruppen\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(5, 13):\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(1, 3) or idx == 14:\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "                \n",
    "    if sheet == \"Locations\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0 or idx == 1:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(7, 10) or idx in range(12, 16) or idx == 17:\n",
    "                print([\"R\", idxx, i])\n",
    "            elif idx in range(2, 4) or idx == 6 or idx in range(10, 12) or idx == 16:\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"N\", idxx])\n",
    "    \n",
    "    if sheet == \"Städte\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(1, 4) or idx in range(5, 7):\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"R\", idxx, i])\n",
    "    \n",
    "    if sheet == \"Länder\":\n",
    "        for idx, i in enumerate(df.columns):\n",
    "            idxx = str(idx).zfill(2)\n",
    "            if idx == 0:\n",
    "                print(\"Referenzliste zum splitten und replacen; I=ID R=reference L=literal N=None\\n\\nrefreplace für I und R, split für R, erst split dann refreplace\\n\")\n",
    "                print([\"I\", idxx, i])\n",
    "            elif idx in range(1, 6):\n",
    "                print([\"L\", idxx, i])\n",
    "            else:\n",
    "                print([\"R\", idxx, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uri_list(column2, predicate, column=\"ID\"):\n",
    "    if isinstance(row[column], list):\n",
    "        idid = row[column][0] ## weil id immer einzigartig ist\n",
    "        if isinstance(row[column2], list):\n",
    "            for i in row[column2]:\n",
    "                graph.add((nvt[idid], predicate, nvt[str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_list(column2, predicate, column=\"ID\"):\n",
    "    if isinstance(row[column], list):\n",
    "        idid = row[column][0] ## weil id immer einzigartig ist\n",
    "        if isinstance(row[column2], list):\n",
    "            for i in row[column2]:\n",
    "                uri = URIRef(i.strip()) ## strip an dieser Stelle weil ichs nich in supersplit hinbekommen habe\n",
    "                graph.add((nvt[idid], predicate, uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lit_list(column2, predicate, column=\"ID\"):\n",
    "    if isinstance(row[column], list):\n",
    "        idid = row[column][0]\n",
    "        if isinstance(row[column2], str) or isinstance(row[column2], datetime.datetime):\n",
    "            graph.add((nvt[idid], predicate, Literal(row[column2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uri_type(column, uri_type):\n",
    "    if isinstance(row[column], list):\n",
    "        for i in row[column]:\n",
    "            graph.add((nvt[i], rdf.type, uri_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='Produktionen', header=1) ## load productions sheet with header in row 1 (row 0 is ignored i think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Videos_zweite_Runde',\n",
       " 'Videos_erste_Runde',\n",
       " 'Produktionen',\n",
       " 'Ereignisse',\n",
       " 'Objekte VIDEOS',\n",
       " 'Objekte TEXT',\n",
       " 'Objekte BILD',\n",
       " 'Objekte AUDIO',\n",
       " '||_Personen',\n",
       " '||_Gruppen_Ensembles',\n",
       " '||_Veranstaltungsort',\n",
       " '||_Städte',\n",
       " '||_Länder',\n",
       " 'Sammlungen',\n",
       " 'Serie',\n",
       " 'TYPEN und GLOSSARE',\n",
       " 'Fragen und Dok',\n",
       " 'TODOs',\n",
       " 'Legende',\n",
       " 'Unterobjekt Beispiele',\n",
       " 'Übersicht']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.ExcelFile('./NVT_Metadatentabelle_MASTER_0706.xlsm').sheet_names ## load Excel File to display sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='Ereignisse', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='Objekte VIDEOS', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='Objekte TEXT', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='Objekte BILD', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='Objekte AUDIO', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personen = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='||_Personen', header=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gruppen = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='||_Gruppen_Ensembles', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='||_Veranstaltungsort', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadt = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='||_Städte', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='||_Länder', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sammlung = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='Sammlungen', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = pd.read_excel('./NVT_Metadatentabelle_MASTER_0706.xlsm', sheet_name='Serie', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnref(pr_clean, sheet=\"Produktionen\")\n",
    "# columnref(ev_clean, sheet=\"Ereignisse\")\n",
    "# columnref(vid_clean, sheet=\"Videos\")\n",
    "# columnref(text_clean, sheet=\"Text\")\n",
    "# columnref(img_clean, sheet=\"Bild\")\n",
    "# columnref(aud_clean, sheet=\"Audio\")\n",
    "# columnref(person_clean, sheet=\"Personen\")\n",
    "# columnref(group_clean, sheet=\"Gruppen\")\n",
    "# columnref(loc_clean, sheet=\"Locations\")\n",
    "# columnref(city_clean, sheet=\"Städte\")\n",
    "# columnref(country_clean, sheet=\"Länder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr_clean.to_excel(\"output_pr_clean.xlsx\")\n",
    "# pr_clean.loc[0,:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_clean = (productions[productions['Identifier / geeinigter Name'].str.contains('PR', na=False)] ## drops all rows that don't start with 'PR' or are NaN\n",
    "            .drop(['Musik (für GEMA)'], axis='columns') ## drops unmodeled column, muss nicht sein, kann in Zukunft auch entfernt werden\n",
    "            .drop([2]) ## drops example row\n",
    "            .sort_values(productions.columns[0])\n",
    "            .rename(columns={'Identifier / geeinigter Name':'ID', ## renames columns for future reference\n",
    "                              'Produktionsname / Titel':'PR_Titel',\n",
    "                              'Quelle (Beschreibung)':'Q_Beschreibung',\n",
    "                              'Verwendete Texte':'Verwendete_Texte',\n",
    "                              'Autor(en) der Texte':'Autoren_Texte',\n",
    "                              'Beteiligte Gruppen / Compagnies':'Beteiligte_Gruppen',\n",
    "                              'Sprecher*in':'SprecherIn',\n",
    "                              'Darsteller allgem.':'Darsteller',\n",
    "                              'Weitere Mitwirkende':'Mitwirkende',\n",
    "                              'Spielzeit / Laufzeit Start':'Spielzeit_Start',\n",
    "                              'Spielzeit / Laufzeit Ende':'Spielzeit_Ende'\n",
    "                           }\n",
    "                   )\n",
    "            .reset_index(drop=True) ## resets index to be continouus\n",
    "           )\n",
    "pr_clean = merge_columns(pr_clean, \"Spielzeit_Start\", \"Spielzeit_Ende\", result = \"season\") ## in Zukunft vllt nur Keyword, wenn Tabellentitel angepasst sind\n",
    "pr_clean = merge_columns(pr_clean, \"Verwendete_Texte\", \"Autoren_Texte\", result = \"texts\") ## in Zukunft müssten die Autoren mit der Personentabelle abgeglichen werden, am besten trotzdem noch als literal\n",
    "pr_clean = merge_columns(pr_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "\n",
    "pr_clean.iloc[:, [0]] = splitreplace(pr_clean.iloc[:, [0]])\n",
    "pr_clean.iloc[:, 6:27] = splitreplace(pr_clean.iloc[:, 6:27])\n",
    "pr_clean.iloc[:, 31:35] = splitreplace(pr_clean.iloc[:, 31:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_clean = (events[events['Identifier / geeinigter Name'].str.contains('EV', na=False)]\n",
    "            .drop(events[events['Identifier / geeinigter Name'].str.contains('EV_Internationaler_Workshop_zur_Biomechanik_GITIS Moskau_Januar_1993_001', na=False)].index) ## drops example line\n",
    "            .sort_values(events.columns[0])\n",
    "            .rename(columns={'Identifier / geeinigter Name':'ID', ## renames columns for future reference\n",
    "                             'Ereignisname / Ereignistitel':'EV_Titel',\n",
    "                             'Quelle (Beschreibung)':'Q_Beschreibung',\n",
    "                             'Gehört zu Produktion':'Gehört_PR',\n",
    "                             'Erwähnung von':'Erwähnung_von',\n",
    "                             'Bezug auf / Über / zentraler Gegenstand (Subject)':'Subject',\n",
    "                             'Teilereignis von':'Teilereignis_von',\n",
    "                             'Beteiligte Gruppen / Compagnies':'Beteiligte_Gruppen',\n",
    "                             'Sprecher*in':'SprecherIn',\n",
    "                             'Darsteller allgem.':'Darsteller',\n",
    "                             'Lehrer  / Workshopleiter':'Lehrer',\n",
    "                             'Weitere Mitwirkende':'Mitwirkende',\n",
    "                             'Zeitpunkt (Datum)':'Zeitpunkt',\n",
    "                             'Zeitraum Start':'Zeitraum_Start',\n",
    "                             'Zeitraum Ende':'Zeitraum_Ende'\n",
    "                           }\n",
    "                   )\n",
    "            .reset_index(drop=True) ## resets index to be continouus\n",
    "           )\n",
    "ev_clean = merge_columns(ev_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "ev_clean = merge_columns(ev_clean, \"Zeitraum_Start\", \"Zeitraum_Ende\", result = \"zeitraum\")\n",
    "\n",
    "ev_clean.iloc[:, 5:31] = splitreplace(ev_clean.iloc[:, 5:31])\n",
    "ev_clean.iloc[:, [0, 2, 35, 36, 37, 39]] = splitreplace(ev_clean.iloc[:, [0, 2, 35, 36, 37, 39]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_clean = (videos[videos['Projekt ID'].str.contains('vid', na=False)]\n",
    "             .sort_values(videos.columns[2])\n",
    "             .rename(columns={'Projekt ID':'ID',\n",
    "                              'andere IDs':'andere_ID',\n",
    "                              'Unterobjekt von':'Unterobjekt_von',\n",
    "                              'Serie / Abfolge':'Serie',\n",
    "                              'Sammlung (Projekt / DB)':'Sammlung',\n",
    "                              'Gleicher Inhalt':'Gleicher_Inhalt',\n",
    "                              'Abgebildete Produktionen':'Abgebildete_Produktionen',\n",
    "                              'Erwähnte Produktionen':'Erwähnte_Produktionen',\n",
    "                              'Annotation/Beschreibung':'Beschreibung',\n",
    "                              'Quelle (Annotation)':'Q_Beschreibung',\n",
    "                              'Abgebildete Ereignisse':'Abgebildete_Ereignisse',\n",
    "                              'Erwähnte Ereignisse':'Erwähnte_Ereignisse',\n",
    "                              'Kamera / Aufzeichner':'Kamera_Aufzeichner',\n",
    "                              'Sichtbare Entitäten':'Sichtbare_Entitäten',\n",
    "                              'Hörbare Entitäten':'Hörbare_Entitäten',\n",
    "                              '(Irgendwie) Erwähnte Entitäten':'Erwähnte_Entitäten',\n",
    "                              'Erwähnte Gruppen / Compagnies':'Erwähnte_Gruppen',\n",
    "                              'Beitragsregie / Fernsehregie':'Beitragsregie_Fernsehregie',\n",
    "                              'Sprecher*in':'SprecherIn',\n",
    "                              'Darsteller allgem.':'Darsteller',\n",
    "                              'Weitere Mitwirkende':'Mitwirkende',\n",
    "                              'Sprache des Objekts':'Sprache_Objekt',\n",
    "                              'Länge gesamtes Band':'Länge_Band',\n",
    "                              'Zustand':'Zustand_Phys',\n",
    "                              'Objekt identisch mit':'Objekt_identisch_mit',\n",
    "                              'Zustand.1':'Zustand_Digi'                              \n",
    "                             }\n",
    "                    )\n",
    "             .reset_index(drop=True) ## resets index to be continouus             \n",
    "            )\n",
    "vid_clean = merge_columns(vid_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "vid_clean = merge_columns(vid_clean, \"Zustand_Phys\", \"Datum Zustandsaufnahme\", result = \"condition\")\n",
    "vid_clean = physicaldigital(vid_clean, \"ID\")\n",
    "\n",
    "vid_clean.iloc[:, [2, 68, 69]] = splitreplace(vid_clean.iloc[:, [2, 68, 69]])\n",
    "vid_clean.iloc[:, 7:16] = splitreplace(vid_clean.iloc[:, 7:16])\n",
    "vid_clean.iloc[:, 20:44] = splitreplace(vid_clean.iloc[:, 20:44])\n",
    "vid_clean.iloc[:, 47:50] = splitreplace(vid_clean.iloc[:, 47:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean = (text[text['Projekt ID'].str.contains('txt', na=False)]\n",
    "              .sort_values(text.columns[2])\n",
    "              .rename(columns={'Projekt ID':'ID',\n",
    "                               'andere IDs':'andere_ID',\n",
    "                               'Unterobjekt von':'Unterobjekt_von',\n",
    "                               'Bildserie':'Serie',\n",
    "                               'Sammlung (Projekt / DB)':'Sammlung',\n",
    "                               'Gleiche Inhalte':'Gleicher_Inhalt',\n",
    "                               'Abgebildete Produktionen':'Abgebildete_Produktionen',\n",
    "                               'Erwähnte Produktionen':'Erwähnte_Produktionen',\n",
    "                               'Abgebildete Ereignisse':'Abgebildete_Ereignisse',\n",
    "                               'Erwähnte Ereignisse':'Erwähnte_Ereignisse',\n",
    "                               'Annotation/Beschreibung':'Beschreibung',\n",
    "                               'Quelle (Annotation)':'Q_Beschreibung',\n",
    "                               'Herausgeberschaft (Institution / Verlag)':'Herausgeberschaft',\n",
    "                               'Herausgeber*in (Person)':'HerausgeberIn',\n",
    "                               'Autor*in':'AutorIn',\n",
    "                               'Übersetzer*in':'ÜbersetzerIn',\n",
    "                               'Layout/Satz':'Layout',\n",
    "                               'Grafik/künstl. Gestaltung':'Grafik_Gestaltung',\n",
    "                               'Weitere Mitwirkende':'Mitwirkende',\n",
    "                               'Erwähnung Personen':'Erwähnung_Personen',\n",
    "                               'Erwähnte Gruppen':'Erwähnung_Gruppen',\n",
    "                               'Sichtbare Personen':'Sichtbare_Personen',\n",
    "                               'Sichtbare Gruppen':'Sichtbare_Gruppen',\n",
    "                               'Erstausgabe (der vorliegenden Sprache)':'Erstausgabe_Sprache',\n",
    "                               'Erscheinungsstadt ':'Erscheinungsstadt',\n",
    "                               'Anzahl Exemplare':'Anzahl_Exemplare',\n",
    "                               'Format (Dimensionen)':'Phys_Format',\n",
    "                               'Zustand':'Zustand_Phys',\n",
    "                               'Datum Zustandsaufnahme':'Datum_Zustandsaufnahme',\n",
    "                               'Objekt identisch mit':'Objekt_identisch_mit',\n",
    "                               'Zustand.1':'Zustand_Digi'\n",
    "                              }\n",
    "                     )\n",
    "              .reset_index(drop=True) ## resets index to be continouus             \n",
    "             )\n",
    "text_clean = merge_columns(text_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "text_clean = merge_columns(text_clean, \"Zustand_Phys\", \"Datum_Zustandsaufnahme\", result = \"condition\")\n",
    "text_clean = physicaldigital(text_clean, \"ID\")\n",
    "\n",
    "text_clean.iloc[:, [2, 38, 40, 52, 59, 60]] = splitreplace(text_clean.iloc[:, [2, 38, 40, 52, 59, 60]])\n",
    "text_clean.iloc[:, 7:16] = splitreplace(text_clean.iloc[:, 7:16])\n",
    "text_clean.iloc[:, 22:34] = splitreplace(text_clean.iloc[:, 22:34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_clean = (images[images['Projekt ID'].str.contains('img', na=False)]\n",
    "             .sort_values(images.columns[2])\n",
    "             .rename(columns={'Projekt ID':'ID',\n",
    "                              'andere IDs':'andere_ID',\n",
    "                              'Unterobjekt von':'Unterobjekt_von',\n",
    "                              'Bildserie':'Serie',\n",
    "                              'Sammlung (Projekt / DB)':'Sammlung',\n",
    "                              'Gleiches Motive':'Gleicher_Inhalt',\n",
    "                              'Abgebildete Produktionen':'Abgebildete_Produktionen',\n",
    "                              'Erwähnte Produktionen':'Erwähnte_Produktionen',\n",
    "                              'Abgebildete Ereignisse':'Abgebildete_Ereignisse',\n",
    "                              'Erwähnte Ereignisse':'Erwähnte_Ereignisse',\n",
    "                              'Motivbeschreibung':'Beschreibung',\n",
    "                              'Quelle (Beschreibung)':'Q_Beschreibung',\n",
    "                              'abgebildete Entitäten':'abgebildete_Entitäten',\n",
    "                              'Fotograf*in':'FotografIn',\n",
    "                              'Aufnahmedatum/Entstehungsdatum':'Aufnahmedatum',\n",
    "                              'Beschriftung + Markierungen (vorn)':'Beschriftung_Vorn',\n",
    "                              'Beschriftung + Markierungen (hinten)':'Beschriftung_Hinten',\n",
    "                              'Bildtyp/ Träger':'Träger',\n",
    "                              'Farbe (nach AAT)':'Farbe',\n",
    "                              'Zustand':'Zustand_Phys',\n",
    "                              'Datum Zustandsaufnahme':'Datum_Zustandsaufnahme',\n",
    "                              'Objekt identisch mit':'Objekt_identisch_mit',\n",
    "                              'Zustand.1':'Zustand_Digi'\n",
    "                             }\n",
    "                    )\n",
    "                    .reset_index(drop=True) ## resets index to be continouus          \n",
    "            )\n",
    "\n",
    "img_clean = merge_columns(img_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "img_clean = merge_columns(img_clean, \"Zustand_Phys\", \"Datum_Zustandsaufnahme\", result = \"condition\")\n",
    "img_clean = physicaldigital(img_clean, \"ID\")\n",
    "\n",
    "img_clean.iloc[:, [2, 20, 21, 24, 25, 26, 38, 45, 46]] = splitreplace(img_clean.iloc[:, [2, 20, 21, 24, 25, 26, 38, 45, 46]])\n",
    "img_clean.iloc[:, 8:17] = splitreplace(img_clean.iloc[:, 8:17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_clean = (audio[audio['Projekt ID'].str.contains('aud', na=False)]\n",
    "             .sort_values(audio.columns[2])\n",
    "             .rename(columns={'Projekt ID':'ID',\n",
    "                              'andere IDs':'andere_ID',\n",
    "                              'Unterobjekt von':'Unterobjekt_von',\n",
    "                              'Sammlung (Projekt / DB)':'Sammlung',\n",
    "                              'Gleiche Aufnahme':'Gleicher_Inhalt',\n",
    "                              'Abgebildete Produktionen':'Abgebildete_Produktionen',\n",
    "                              'Erwähnte Produktionen':'Erwähnte_Produktionen',\n",
    "                              'Abgebildete Ereignisse':'Abgebildete_Ereignisse',\n",
    "                              'Erwähnte Ereignisse':'Erwähnte_Ereignisse',\n",
    "                              'Annotation/Beschreibung':'Beschreibung',\n",
    "                              'Quelle (Annotation)':'Q_Beschreibung',\n",
    "                              'Hörbare Entitäten':'Hörbare_Entitäten',\n",
    "                              '(Irgendwie) Erwähnte Entitäten':'Erwähnte_Entitäten',\n",
    "                              'Aufzeichner*in':'AufzeichnerIn',\n",
    "                              'Beitragsregie / Radioregie':'Beitragsregie',\n",
    "                              'Erwähnte Gruppen / Compagnies':'Erwähnte_Gruppen',\n",
    "                              'Sprache des Objekts':'Sprache',\n",
    "                              'Audioträger / Typ':'Träger',\n",
    "                              'Länge gesamtes Band':'Länge_Band',\n",
    "                              'Zustand':'Zustand_Phys',\n",
    "                              'Datum Zustandsaufnahme':'Datum_Zustandsaufnahme',\n",
    "                              'Objekt identisch mit':'Objekt_identisch_mit',\n",
    "                              'Zustand.1':'Zustand_Digi'\n",
    "                             }\n",
    "                    )\n",
    "             .reset_index(drop=True) ## resets index to be continouus                    \n",
    "            )\n",
    "aud_clean = merge_columns(aud_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "aud_clean = merge_columns(aud_clean, \"Zustand_Phys\", \"Datum_Zustandsaufnahme\", result = \"condition\")\n",
    "aud_clean = physicaldigital(aud_clean, \"ID\")\n",
    "\n",
    "aud_clean.iloc[:, [2, 28, 29, 30, 40, 48, 49]] = splitreplace(aud_clean.iloc[:, [2, 28, 29, 30, 40, 48, 49]])\n",
    "aud_clean.iloc[:, 7:16] = splitreplace(aud_clean.iloc[:, 7:16])\n",
    "aud_clean.iloc[:, 20:25] = splitreplace(aud_clean.iloc[:, 20:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_clean = (personen[personen['Identifier / geeinigte Schreibweise'].str.contains(',', na=False)]\n",
    "                .drop(personen[personen['Identifier / geeinigte Schreibweise'].str.contains('Vorname Vatersname,Nachname', na=False)].index)\n",
    "                .sort_values(personen.columns[0])\n",
    "                .rename(columns={\"Identifier / geeinigte Schreibweise\":\"ID\",\n",
    "                                \"Quelle (Beschreibung)\":\"Q_Beschreibung\"}\n",
    "                       )\n",
    "                .reset_index(drop=True) ## resets index to be continouus     \n",
    "               )\n",
    "\n",
    "person_clean = merge_columns(person_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "\n",
    "person_clean.iloc[:, [0]] = splitreplace(person_clean.iloc[:, [0]])\n",
    "person_clean.iloc[:, 9:15] = person_clean.iloc[:, 9:15].apply(supersplit, axis=1) ## weil die inhalte weblinks sind kein str.replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_clean = (gruppen[gruppen['Gruppe Identifier / geeinigte Schreibweise'].str.contains('G_', na=False)]\n",
    "                .sort_values(gruppen.columns[0])\n",
    "                .rename(columns={\"Gruppe Identifier / geeinigte Schreibweise\":\"ID\",\n",
    "                                \"präferierter Name\":\"Name\",\n",
    "                                \"weitere Namen\":\"Namen\",\n",
    "                                \"Quelle Beschreibung\":\"Q_Beschreibung\",\n",
    "                                \"ist Vorgänger von\":\"Vorgänger_von\",\n",
    "                                \"ist Nachfolger von\":\"Nachfolger_von\",\n",
    "                                \"ist ansässig Stadt\":\"ansässig_Stadt\",\n",
    "                                \"ist ansässig Land\":\"ansässig_Land\",\n",
    "                                 \"ist ansässig Haus\":\"ansässig_Haus\",\n",
    "                                 \"WIKIDATA URI\":\"Wikidata\"\n",
    "                                }\n",
    "                       )\n",
    "                .reset_index(drop=True) ## resets index to be continouus     \n",
    "               )\n",
    "\n",
    "group_clean = merge_columns(group_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "group_clean.iloc[:, [0, 5, 6, 7, 8, 9]] = splitreplace(group_clean.iloc[:, [0, 5, 6, 7, 8, 9]])\n",
    "group_clean.iloc[:, [10, 11, 12]] = group_clean.iloc[:, [10, 11, 12]].apply(supersplit, axis=1) ## weil die inhalte weblinks sind kein str.replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_clean = (location[location['PROJEKT'].str.contains('LOC_', na=False)]\n",
    "             .sort_values(location.columns[0])\n",
    "             .rename(columns={\"PROJEKT\":\"ID\",\n",
    "                              \"ist Institution\":\"ist_Institution\",\n",
    "                              \"präferierter Ortsname\":\"Ortsname\",\n",
    "                              \"weitere Ortsnamen\":\"weitere_Ortsnamen\",\n",
    "                              \"Quelle Beschreibung\":\"Q_Beschreibung\",\n",
    "                              \"Gehört Zu\":\"Gehört_Zu\",\n",
    "                              \"geo:LAT\":\"LAT\",\n",
    "                              \"geo:LONG\":\"LONG\",\n",
    "                              \"Wikipedia URI\":\"Wikipedia\",\n",
    "                              \"GND URI\":\"GND\",\n",
    "                              \"WIKIDATA URI\":\"WIKIDATA\",\n",
    "                              \"geonames URI\":\"geonames\"\n",
    "                             }\n",
    "                    )\n",
    "             .reset_index(drop=True) ## resets index to be continouus\n",
    "            )\n",
    "loc_clean = merge_columns(loc_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "loc_clean = merge_columns(loc_clean, \"ID\", \"ist_Institution\", result=\"institution\")\n",
    "loc_clean.iloc[:, [0, 7, 8, 9, 17]] = splitreplace(loc_clean.iloc[:, [0, 7, 8, 9, 17]])\n",
    "loc_clean.iloc[:, 12:16] = loc_clean.iloc[:, 12:16].apply(supersplit, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_clean = (stadt.sort_values(stadt.columns[0])\n",
    "              .rename(columns={\"Stadt Identifier / geeinigte Schreibweise\":\"ID\",\n",
    "                               \"präferierter Stadtname\":\"präf_Stadtname\",\n",
    "                               \"Stadtname DE\":\"Stadtname_DE\",\n",
    "                               \"Stadtname EN\":\"Stadtname_EN\",\n",
    "                               \"LAND (Ref)\":\"Land\",\n",
    "                               \"geo:LAT\":\"LAT\",\n",
    "                               \"geo:LONG\":\"LONG\",\n",
    "                               \"geonames URI\":\"geonames\"\n",
    "                              }\n",
    "                     )\n",
    "              .reset_index(drop=True) ## resets index to be continouus\n",
    "             )\n",
    "city_clean.iloc[:, [0, 4]] = splitreplace(city_clean.iloc[:, [0, 4]])\n",
    "city_clean.iloc[:, [7]] = city_clean.iloc[:, [7]].apply(supersplit, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_clean = (land.sort_values(land.columns[0])\n",
    "              .rename(columns={\"Länder Identifier / geeinigte Schreibweise\":\"ID\",\n",
    "                               \"präferierter Ländername\":\"präf_Landname\",\n",
    "                               \"Ländername DE\":\"Landname_DE\",\n",
    "                               \"Ländername EN\":\"Landname_EN\",\n",
    "                               \"geo:LAT\":\"LAT\",\n",
    "                               \"geo:LONG\":\"LONG\",\n",
    "                               \"geonames URI\":\"geonames\"\n",
    "                              }\n",
    "                     )\n",
    "              .reset_index(drop=True) ## resets index to be continouus\n",
    "             )\n",
    "country_clean.iloc[:, [0]] = splitreplace(country_clean.iloc[:, [0]])\n",
    "country_clean.iloc[:, [6]] = country_clean.iloc[:, [6]].apply(supersplit, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_clean = (sammlung[sammlung['PROJEKT'].str.contains('COL_', na=False)]\n",
    "             .sort_values(sammlung.columns[0])\n",
    "             .rename(columns={\"PROJEKT\":\"ID\",\n",
    "                              \"Sammlungsbeschreibung\":\"Beschreibung\",\n",
    "                              \"Quelle der Beschreibung\":\"Q_Beschreibung\"\n",
    "                             }\n",
    "                    )\n",
    "             .reset_index(drop=True)\n",
    "            )\n",
    "col_clean.iloc[:, [0]] = splitreplace(col_clean.iloc[:, [0]])\n",
    "col_clean = merge_columns(col_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROJEKT</th>\n",
       "      <th>Serientitel</th>\n",
       "      <th>Serienbeschreibung</th>\n",
       "      <th>Quelle der Beschreibung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Referenz</td>\n",
       "      <td>Text</td>\n",
       "      <td>Text</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Identifier / geeinigte Schreibweise</td>\n",
       "      <td>Serientitel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRS_Identifier</td>\n",
       "      <td>Titel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               PROJEKT  Serientitel Serienbeschreibung  \\\n",
       "0                             Referenz         Text               Text   \n",
       "1  Identifier / geeinigte Schreibweise  Serientitel                NaN   \n",
       "2                       SRS_Identifier        Titel                NaN   \n",
       "\n",
       "  Quelle der Beschreibung  \n",
       "0                    Text  \n",
       "1                     NaN  \n",
       "2                     NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Serientitel</th>\n",
       "      <th>Beschreibung</th>\n",
       "      <th>Q_Beschreibung</th>\n",
       "      <th>Beschreibung_Quelle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, Serientitel, Beschreibung, Q_Beschreibung, Beschreibung_Quelle]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_clean = (serie[serie['PROJEKT'].str.contains('SRS_', na=False)]\n",
    "                .drop(serie[serie['PROJEKT'].str.contains('SRS_Identifier', na=False)].index)\n",
    "                .sort_values(serie.columns[0])\n",
    "                .rename(columns={\"PROJEKT\":\"ID\",\n",
    "                                 \"Serienbeschreibung\":\"Beschreibung\",\n",
    "                                 \"Quelle der Beschreibung\":\"Q_Beschreibung\"\n",
    "                                }\n",
    "                       )\n",
    "                .reset_index(drop=True)\n",
    "               )\n",
    "series_clean.iloc[:, [0]] = splitreplace(series_clean.iloc[:, [0]])\n",
    "series_clean = merge_columns(series_clean, \"Beschreibung\", \"Q_Beschreibung\", result = \"description\")\n",
    "series_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in pr_clean.iterrows():\n",
    "    \n",
    "    graph = pr_graph\n",
    "    ##id_id = str(row[\"ID\"][0])\n",
    "    \n",
    "    uri_type(\"ID\", nvto.PerformingArtsProduction)\n",
    "    \n",
    "    lit_list(\"PR_Titel\", dcterms.title)\n",
    "    lit_list(\"PR_Titel\", skos.prefLabel)\n",
    "    lit_list(\"Premierendatum\", nvto.hasFirstPerformanceDate)\n",
    "    lit_list(\"Premierendatum\", nvto.hasLastPerformanceDate)\n",
    "    \n",
    "    uri_list(\"Produktionstyp\", dcterms.type)\n",
    "    uri_list(\"Beteiligte_Gruppen\", dcterms.contributor)\n",
    "    uri_list(\"Konzept\", nvto.hasConceptOriginator)\n",
    "    uri_list(\"Textbearbeitung\", nvto.hasAdaptor)\n",
    "    uri_list(\"Übersetzung\", nvto.hasTranslator)\n",
    "    uri_list(\"Regie\", nvto.hasDirector)\n",
    "    uri_list(\"SprecherIn\", nvto.hasSpeaker)\n",
    "    uri_list(\"Choreographie\", nvto.hasChoreographer)\n",
    "    uri_list(\"Dramaturgie\", nvto.hasDramaturge)\n",
    "    uri_list(\"Bühnenbild\", nvto.hasSetDesigner)\n",
    "    uri_list(\"Kostümdesgin\", nvto.hasCostumedesigner)\n",
    "    uri_list(\"Figurenbau\", nvto.hasPuppetDesigner)\n",
    "    uri_list(\"Maskenbau\", nvto.hasMaskDesigner)\n",
    "    uri_list(\"Lichtdesign\", nvto.hasLightDesigner)\n",
    "    uri_list(\"Videodesign\", nvto.hasVideoDesigner)\n",
    "    uri_list(\"Schauspieler\", nvto.hasActor)\n",
    "    uri_list(\"Tänzer\", nvto.hasDancer)\n",
    "    uri_list(\"Darsteller\", nvto.hasPerformer)\n",
    "    uri_list(\"Musiker\", nvto.hasMusician)\n",
    "    uri_list(\"Komposition\", nvto.hasComposer)\n",
    "    uri_list(\"Mitwirkende\", dcterms.contributor)\n",
    "    uri_list(\"Veranstaltungsort\", nvto.happenedAtPlace)\n",
    "    uri_list(\"Stadt\", nvto.happenedAtPlace)\n",
    "    uri_list(\"Land\", nvto.happenedAtPlace)\n",
    "    uri_list(\"Spielzeit\", nvto.hasSeason)\n",
    "    uri_type(\"Spielzeit\", nvto.TimeSpan)\n",
    "    uri_type(\"Konzept\", skos.Concept)\n",
    "    \n",
    "    lit_list(\"Spielzeit_Start\", nvto.beginsAtTime, \"Spielzeit\")\n",
    "    lit_list(\"Spielzeit_Ende\", nvto.endsAtTime, \"Spielzeit\")\n",
    "    \n",
    "    lit_list(\"Texte_Autoren\", dcterms.description)\n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in ev_clean.iterrows():\n",
    "    \n",
    "    graph = ev_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.Event)\n",
    "    \n",
    "    lit_list(\"EV_Titel\", skos.prefLabel)\n",
    "    \n",
    "    uri_list(\"Ereignisart\", dcterms.type)\n",
    "    uri_list(\"Gehört_PR\", dcterms.isPartOf)\n",
    "    uri_list(\"Erwähnung_von\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Subject\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Teilereignis_von\", dcterms.isPartOf)\n",
    "    uri_list(\"Beteiligte_Gruppen\", dcterms.contributor)\n",
    "    uri_list(\"Konzept\", nvto.hasConceptOriginator)\n",
    "    uri_list(\"Textbearbeitung\", nvto.hasAdaptor)\n",
    "    uri_list(\"Übersetzung\", nvto.hasTranslator)\n",
    "    uri_list(\"Regie\", nvto.hasDirector)\n",
    "    uri_list(\"SprecherIn\", nvto.hasSpeaker)\n",
    "    uri_list(\"Choreographie\", nvto.hasChoreographer)\n",
    "    uri_list(\"Dramaturgie\", nvto.hasDramaturge)\n",
    "    uri_list(\"Bühnenbild\", nvto.hasSetDesigner)\n",
    "    uri_list(\"Kostümdesgin\", nvto.hasCostumedesigner)\n",
    "    uri_list(\"Figurenbau\", nvto.hasPuppetDesigner)\n",
    "    uri_list(\"Maskenbau\", nvto.hasMaskDesigner)\n",
    "    uri_list(\"Lichtdesign\", nvto.hasLightDesigner)\n",
    "    uri_list(\"Videodesign\", nvto.hasVideoDesigner)\n",
    "    uri_list(\"Schauspieler\", nvto.hasActor)\n",
    "    uri_list(\"Tänzer\", nvto.hasDancer)\n",
    "    uri_list(\"Darsteller\", nvto.hasPerformer)\n",
    "    uri_list(\"Musiker\", nvto.hasMusician)\n",
    "    uri_list(\"Komposition\", nvto.hasComposer)\n",
    "    uri_list(\"Lehrer\", dcterms.mediator)\n",
    "    uri_list(\"Teilnehmer\", nvto.hasParticipant)\n",
    "    uri_list(\"Mitwirkende\", dcterms.contributor)\n",
    "    \n",
    "    lit_list(\"Zeitpunkt\", dcterms.date)\n",
    "    lit_list(\"Zeitraum_Start\", nvto.beginsAtTime, \"Zeitraum\")\n",
    "    lit_list(\"Zeitraum_Ende\", nvto.endsAtTime, \"Zeitraum\")\n",
    "    \n",
    "    uri_list(\"Veranstaltungsort\", nvto.happenedAtPlace)\n",
    "    uri_list(\"Stadt\", nvto.happenedAtPlace)\n",
    "    uri_list(\"Land\", nvto.happenedAtPlace)\n",
    "    \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.source)\n",
    "    \n",
    "    uri_list(\"Zeitraum\", nvto.hasSeason)\n",
    "    \n",
    "    uri_type(\"Zeitraum\", nvto.TimeSpan)\n",
    "    uri_type(\"Ereignisart\", skos.Concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in vid_clean.iterrows():\n",
    "    \n",
    "    graph = vid_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.InformationObject)\n",
    "    \n",
    "    uri_list(\"Phys_ID\", nvto.hasInformationCarrier)\n",
    "    uri_list(\"Digi_ID\", nvto.hasInformationCarrier)\n",
    "    uri_list(\"Digi_ID\", nvto.hasDigitalVersion, \"Phys_ID\")\n",
    "    \n",
    "    uri_type(\"Phys_ID\", nvto.PhysicalObject)\n",
    "    uri_type(\"Digi_ID\", nvto.DigitalObject)\n",
    "    \n",
    "    lit_list(\"andere_ID\", dcterms.identifier)\n",
    "    \n",
    "    uri_list(\"Archivalientyp\", dcterms.type)\n",
    "    uri_type(\"Archivalientyp\", skos.Concept)\n",
    "    uri_list(\"Unterobjekt_von\", dcterms.isPartOf)\n",
    "    uri_list(\"Serie\", dcterms.isPartOf)\n",
    "    uri_list(\"Sammlung\", dcterms.isPartOf)\n",
    "    uri_list(\"Gleicher_Inhalt\", nvto.hasContentMatch)\n",
    "    uri_list(\"Abgebildete_Produktionen\", nvto.containsAudioVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Produktionen\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Abgebildete_Ereignisse\", nvto.containsAudioVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Ereignisse\", nvto.containsReferenceTo)\n",
    "    \n",
    "    \n",
    "    lit_list(\"Titel\", skos.prefLabel)\n",
    "    lit_list(\"Titel\", dcterms.title)\n",
    "    lit_list(\"Untertitel\", nvto.hasSubtitle)\n",
    "    \n",
    "    uri_list(\"Kamera_Aufzeichner\", nvto.hasCinematographer)\n",
    "    uri_list(\"Sichtbare_Entitäten\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Hörbare_Entitäten\", nvto.containsAudibleReferenceTo)\n",
    "    uri_list(\"Erwähnte_Entitäten\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Erwähnte_Gruppen\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Autorenschaft\", nvto.hasAuthor)\n",
    "    uri_list(\"Beitragsregie_Fernsehregie\", nvto.hasDirector)\n",
    "    uri_list(\"SprecherIn\", nvto.hasSpeaker)\n",
    "    uri_list(\"Choreographie\", nvto.hasChoreographer)\n",
    "    uri_list(\"Dramaturgie\", nvto.hasDramaturge)\n",
    "    uri_list(\"Bühnenbild\", nvto.hasSetDesigner)\n",
    "    uri_list(\"Maske\", nvto.hasMaskDesigner)\n",
    "    uri_list(\"Lichtdesign\", nvto.hasLightDesigner)\n",
    "    uri_list(\"Videodesign\", nvto.hasVideoDesigner)\n",
    "    uri_list(\"Schauspieler\", nvto.hasActor)\n",
    "    uri_list(\"Tänzer\", nvto.hasDancer)\n",
    "    uri_list(\"Darsteller\", nvto.hasPerformer)\n",
    "    uri_list(\"Musiker\", nvto.hasMusician)\n",
    "    uri_list(\"Komposition\", nvto.hasComposer)\n",
    "    uri_list(\"Mitwirkende\", dcterms.contributor)\n",
    "    uri_list(\"Editor\", nvto.hasVideoEditor)\n",
    "    uri_list(\"Ton\", nvto.hasRecordist)\n",
    "    \n",
    "    lit_list(\"Sprache_Objekt\", dcterms.language)\n",
    "    lit_list(\"Aufnahmedatum\", dcterms.created)\n",
    "    \n",
    "    uri_list(\"Entstehungsort\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Stadt\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Land\", nvto.originatedAtPlace)\n",
    "    \n",
    "    lit_list(\"Rechteinhaber\", dcterms.rightsHolder)\n",
    "    \n",
    "    lit_list(\"Träger\", dcterms.medium, \"Phys_ID\")\n",
    "    lit_list(\"Länge_Band\", dcterms.extent, \"Phys_ID\")\n",
    "    lit_list(\"Herkunft\", dcterms.provenance, \"Phys_ID\")\n",
    "    lit_list(\"Zustand_Datum\", nvto.hasCondition, \"Phys_ID\")\n",
    "    lit_list(\"Copyright\", dcterms.rights, \"Phys_ID\")\n",
    "    \n",
    "    uri_list(\"Objekt_identisch_mit\", nvto.hasContentMatch)\n",
    "    \n",
    "    lit_list(\"Zustand_Digi\", nvto.hasCondition, \"Digi_ID\")\n",
    "    lit_list(\"Länge\", dcterms.extent, \"Digi_ID\")\n",
    "    lit_list(\"Dateiformat\", nvto.hasDigitalFormat, \"Digi_ID\")\n",
    "    \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in text_clean.iterrows():\n",
    "    \n",
    "    graph = text_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.InformationObject)\n",
    "    \n",
    "    uri_list(\"Phys_ID\", nvto.hasInformationCarrier)\n",
    "    uri_list(\"Digi_ID\", nvto.hasInformationCarrier)\n",
    "    \n",
    "    uri_type(\"Phys_ID\", nvto.PhysicalObject)\n",
    "    uri_type(\"Digi_ID\", nvto.DigitalObject)\n",
    "    \n",
    "    uri_list(\"Digi_ID\", nvto.hasDigitalVersion, \"Phys_ID\")\n",
    "    \n",
    "    \n",
    "    lit_list(\"andere_ID\", dcterms.identifier)\n",
    "    \n",
    "    uri_list(\"Archivalientyp\", dcterms.type)\n",
    "    uri_type(\"Archivalientyp\", skos.Concept)\n",
    "    \n",
    "    uri_list(\"Unterobjekt_von\", dcterms.isPartOf)\n",
    "    uri_list(\"Serie\", dcterms.isPartOf)\n",
    "    uri_list(\"Sammlung\", dcterms.isPartOf)\n",
    "    uri_list(\"Gleicher_Inhalt\", nvto.hasContentMatch)\n",
    "    uri_list(\"Abgebildete_Produktionen\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Produktionen\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Abgebildete_Ereignisse\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Ereignisse\", nvto.containsReferenceTo)\n",
    "    \n",
    "    lit_list(\"Titel\", skos.prefLabel)\n",
    "    lit_list(\"Titel\", dcterms.title)\n",
    "    lit_list(\"Untertitel\", nvto.hasSubtitle)\n",
    "    lit_list(\"Inhaltsverzeichnis\", dcterms.tableOfContents)\n",
    "    lit_list(\"Herausgeberschaft\", dcterms.publisher)\n",
    "    \n",
    "    uri_list(\"HerausgeberIn\", dcterms.publisher)\n",
    "    uri_list(\"AutorIn\", nvto.hasAuthor)\n",
    "    uri_list(\"ÜbersetzerIn\", nvto.hasTranslator)\n",
    "    uri_list(\"Layout\", nvto.hasLayouter)\n",
    "    uri_list(\"Grafik_Gestaltung\", nvto.hasIllustrator)\n",
    "    uri_list(\"Redaktion\", nvto.hasEditor)\n",
    "    uri_list(\"Fotografie\", nvto.hasPhotographer)    \n",
    "    uri_list(\"Mitwirkende\", dcterms.contributor)\n",
    "    uri_list(\"Erwähnung_Personen\", nvto.containsTextualReferenceTo)\n",
    "    uri_list(\"Erwähnung_Gruppen\", nvto.containsTextualReferenceTo)\n",
    "    uri_list(\"Sichtbare_Personen\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Sichtbare_Gruppen\", nvto.containsVisualReferenceTo)\n",
    "    \n",
    "    lit_list(\"Verlag\", dcterms.publisher)\n",
    "    lit_list(\"Originalausgabe\", nvto.hasFirstEdition)\n",
    "    lit_list(\"Erstausgabe_Sprache\", nvto.hasFirstLocalizedEdition)\n",
    "    lit_list(\"Erscheinungsdatum\", dcterms.issued)\n",
    "    \n",
    "    uri_list(\"Erscheinungsstadt\", nvto.hasPublishingPlace)\n",
    "    \n",
    "    lit_list(\"Sprache\", dcterms.language)\n",
    "    \n",
    "    uri_list(\"Land\", nvto.hasPublishingPlace)\n",
    "    \n",
    "    lit_list(\"Klassifikation\", dcterms.type)\n",
    "    lit_list(\"Textquelle\", dcterms.source)\n",
    "    lit_list(\"ISBN\", nvto.hasIsbn)\n",
    "    \n",
    "    lit_list(\"Träger\", dcterms.medium, \"Phys_ID\")\n",
    "    lit_list(\"Herkunft\", dcterms.provenance, \"Phys_ID\")\n",
    "    lit_list(\"Umfang\", dcterms.extent, \"Phys_ID\")\n",
    "    lit_list(\"Phys_Format\", dcterms[\"format\"], \"Phys_ID\")\n",
    "    lit_list(\"Zustand_Datum\", nvto.hasCondition, \"Phys_ID\")\n",
    "    lit_list(\"Copyright\", dcterms.rights, \"Phys_ID\")\n",
    "\n",
    "    uri_list(\"Objekt_identisch_mit\", nvto.hasContentMatch)\n",
    "    \n",
    "    lit_list(\"Zustand_Digi\", nvto.hasCondition, \"Digi_ID\")\n",
    "    lit_list(\"Dateiformat\", nvto.hasDigitalFormat, \"Digi_ID\")\n",
    "    \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in img_clean.iterrows():\n",
    "    \n",
    "    graph = img_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.InformationObject)\n",
    "    \n",
    "    uri_list(\"Phys_ID\", nvto.hasInformationCarrier)\n",
    "    uri_list(\"Digi_ID\", nvto.hasInformationCarrier)\n",
    "    \n",
    "    uri_type(\"Phys_ID\", nvto.PhysicalObject)\n",
    "    uri_type(\"Digi_ID\", nvto.DigitalObject)\n",
    "    \n",
    "    uri_list(\"Digi_ID\", nvto.hasDigitalVersion, \"Phys_ID\")\n",
    "    \n",
    "    \n",
    "    lit_list(\"andere_ID\", dcterms.identifier)\n",
    "    \n",
    "    uri_list(\"Archivalientyp\", dcterms.type)\n",
    "    uri_type(\"Archivalientyp\", skos.Concept)\n",
    "    \n",
    "    uri_list(\"Unterobjekt_von\", dcterms.isPartOf)\n",
    "    uri_list(\"Serie\", dcterms.isPartOf)\n",
    "    uri_list(\"Sammlung\", dcterms.isPartOf)\n",
    "    uri_list(\"Gleicher_Inhalt\", nvto.hasContentMatch)\n",
    "    \n",
    "    uri_list(\"Abgebildete_Produktionen\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Produktionen\", nvto.containsTextualReferenceTo)\n",
    "    uri_list(\"Abgebildete_Ereignisse\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"Erwähnte_Ereignisse\", nvto.containsTextualReferenceTo)\n",
    "    \n",
    "    lit_list(\"Bezeichner\", skos.prefLabel)\n",
    "    lit_list(\"Bezeichner\", dcterms.title)\n",
    "    \n",
    "    uri_list(\"abgebildete_Entitäten\", nvto.containsVisualReferenceTo)\n",
    "    uri_list(\"FotografIn\", nvto.hasPhotographer)    \n",
    "    uri_list(\"Fotostudio\", nvto.hasPhotoStudio)\n",
    "    \n",
    "    lit_list(\"Aufnahmedatum\", dcterms.created)\n",
    "    \n",
    "    uri_list(\"Aufnahmeort\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Aufnahmestadt\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Aufnahmeland\", nvto.originatedAtPlace)\n",
    "    \n",
    "    lit_list(\"Beschriftung_Vorn\", nvto.hasLabelingFront, \"Phys_ID\")\n",
    "    lit_list(\"Beschriftung_Hinten\", nvto.hasLabelingBack, \"Phys_ID\")\n",
    "    lit_list(\"Objektbeschreibung\", dcterms.description, \"Phys_ID\")\n",
    "    lit_list(\"Herkunft\", dcterms.provenance, \"Phys_ID\")\n",
    "    \n",
    "    lit_list(\"Rechteinhaber\", dcterms.rightsHolder)\n",
    "        \n",
    "    lit_list(\"Träger\", dcterms.medium, \"Phys_ID\")\n",
    "    \n",
    "    lit_list(\"Farbe\", dcterms[\"format\"])\n",
    "    \n",
    "    lit_list(\"Dimensionen\", nvto.hasDimensions, \"Phys_ID\")\n",
    "    \n",
    "    uri_list(\"Objekt_identisch_mit\", nvto.hasContentMatch)\n",
    "    \n",
    "    lit_list(\"Zustand_Digi\", nvto.hasCondition, \"Digi_ID\")\n",
    "    lit_list(\"Dateiformat\", nvto.hasDigitalFormat, \"Digi_ID\")\n",
    "    \n",
    "    lit_list(\"Copyright\", dcterms.rights, \"Phys_ID\")\n",
    "    \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)\n",
    "    \n",
    "    lit_list(\"Zustand_Datum\", nvto.hasCondition, \"Phys_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in aud_clean.iterrows():\n",
    "    \n",
    "    graph = aud_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.InformationObject)\n",
    "    \n",
    "    uri_list(\"Phys_ID\", nvto.hasInformationCarrier)\n",
    "    uri_list(\"Digi_ID\", nvto.hasInformationCarrier)\n",
    "    \n",
    "    uri_type(\"Phys_ID\", nvto.PhysicalObject)\n",
    "    uri_type(\"Digi_ID\", nvto.DigitalObject)\n",
    "    \n",
    "    uri_list(\"Digi_ID\", nvto.hasDigitalVersion, \"Phys_ID\")\n",
    "    \n",
    "    \n",
    "    lit_list(\"andere_ID\", dcterms.identifier)\n",
    "    \n",
    "    uri_list(\"Archivalientyp\", dcterms.type)\n",
    "    uri_type(\"Archivalientyp\", skos.Concept)\n",
    "    \n",
    "    uri_list(\"Unterobjekt_von\", dcterms.isPartOf)\n",
    "    uri_list(\"Serie\", dcterms.isPartOf)\n",
    "    uri_list(\"Sammlung\", dcterms.isPartOf)\n",
    "    uri_list(\"Gleicher_Inhalt\", nvto.hasContentMatch)\n",
    "    uri_list(\"Abgebildete_Produktionen\", nvto.containsAudibleReferenceTo)\n",
    "    uri_list(\"Erwähnte_Produktionen\", nvto.containsReferenceTo)\n",
    "    uri_list(\"Abgebildete_Ereignisse\", nvto.containsAudibleReferenceTo)\n",
    "    uri_list(\"Erwähnte_Ereignisse\", nvto.containsReferenceTo)\n",
    "    \n",
    "    lit_list(\"Titel\", skos.prefLabel)\n",
    "    lit_list(\"Titel\", dcterms.title)\n",
    "    lit_list(\"Untertitel\", nvto.hasSubtitle)\n",
    "    \n",
    "    uri_list(\"Hörbare_Entitäten\", nvto.containsAudibleReferenceTo)\n",
    "    uri_list(\"Erwähnte_Entitäten\", nvto.containsReferenceTo)\n",
    "    uri_list(\"AufzeichnerIn\", nvto.hasRecordist)\n",
    "    uri_list(\"Beitragsregie\", nvto.hasDirector)\n",
    "    uri_list(\"Erwähnte_Gruppen\", nvto.containsReferenceTo)\n",
    "    \n",
    "    lit_list(\"Aufnahmedatum\", dcterms.created)\n",
    "    lit_list(\"Sprache\", dcterms.language)\n",
    "    \n",
    "    uri_list(\"Entstehungsort\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Stadt\", nvto.originatedAtPlace)\n",
    "    uri_list(\"Land\", nvto.originatedAtPlace)\n",
    "    \n",
    "    lit_list(\"Träger\", dcterms.medium, \"Phys_ID\")\n",
    "    lit_list(\"Länge_Band\", dcterms.extent, \"Phys_ID\")\n",
    "    lit_list(\"Herkunft\", dcterms.provenance, \"Phys_ID\")\n",
    "    \n",
    "    lit_list(\"Rechteinhaber\", dcterms.rightsHolder)\n",
    "    \n",
    "    \n",
    "    uri_list(\"Objekt_identisch_mit\", nvto.hasContentMatch)\n",
    "    \n",
    "    lit_list(\"Zustand_Digi\", nvto.hasCondition, \"Digi_ID\")\n",
    "    lit_list(\"Dateiformat\", nvto.hasDigitalFormat, \"Digi_ID\")\n",
    "    \n",
    "    lit_list(\"Copyright\", dcterms.rights, \"Phys_ID\")\n",
    "    \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)\n",
    "    \n",
    "    lit_list(\"Zustand_Datum\", nvto.hasCondition, \"Phys_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in person_clean.iterrows():\n",
    "    \n",
    "    graph = person_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.Agent)\n",
    "    \n",
    "    lit_list(\"Vollname\", skos.prefLabel)\n",
    "    lit_list(\"Vollname\", foaf.name)\n",
    "    lit_list(\"Vorname\", foaf.firstName)\n",
    "    lit_list(\"Nachname\", foaf.familyName)\n",
    "    lit_list(\"Geboren\", nvto.hasDateOfBirth)\n",
    "    lit_list(\"Gestorben\", nvto.hasDateOfDeath)\n",
    "    \n",
    "    url_list(\"VIAF\", owl.sameAs)\n",
    "    url_list(\"GND\", owl.sameAs)\n",
    "    url_list(\"Wikidata\", owl.sameAs)\n",
    "    url_list(\"Website\", owl.sameAs)\n",
    "    url_list(\"Websites\", owl.sameAs)\n",
    "    url_list(\"dbpedia\", owl.sameAs)\n",
    "        \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in group_clean.iterrows():\n",
    "    \n",
    "    graph = group_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.PerformingArtsGroup)\n",
    "    \n",
    "    lit_list(\"Name\", skos.prefLabel)\n",
    "    lit_list(\"Namen\", skos.altLabel)\n",
    "    \n",
    "    uri_list(\"Vorgänger_von\", nvto.hasPredecessor)\n",
    "    uri_list(\"Nachfolger_von\", nvto.hasSuccessor)\n",
    "    \n",
    "    uri_list(\"ansässig_Stadt\", nvto.hasRelatedPlace)\n",
    "    uri_list(\"ansässig_Land\", nvto.hasRelatedPlace)\n",
    "    uri_list(\"ansässig_Haus\", nvto.hasResidence)\n",
    "    \n",
    "    url_list(\"Website\", foaf.homepage)\n",
    "    url_list(\"Wikidata\", owl.sameAs)\n",
    "    url_list(\"GND URI\", owl.sameAs)\n",
    "        \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in loc_clean.iterrows():\n",
    "    \n",
    "    graph = loc_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.PerformingArtsLocation)\n",
    "    \n",
    "    lit_list(\"Ortsname\", skos.prefLabel)\n",
    "    lit_list(\"weitere_Ortsnamen\", skos.altLabel)\n",
    "    lit_list(\"Adresse\", nvto.hasAddress)\n",
    "    \n",
    "    uri_list(\"Gehört zu\", nvto.isResidenceOf)    \n",
    "    uri_list(\"STADT\", dcterms.isPartOf)\n",
    "    uri_list(\"LAND\", dcterms.isPartOf)\n",
    "    \n",
    "    lit_list(\"LAT\", wgs84_pos.lat)\n",
    "    lit_list(\"LONG\", wgs84_pos.long)\n",
    "    \n",
    "    url_list(\"Wikipedia\", owl.sameAs)\n",
    "    url_list(\"GND\", owl.sameAs)\n",
    "    url_list(\"WIKIDATA\", owl.sameAs)\n",
    "    url_list(\"geonames\", owl.sameAs)\n",
    "        \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)\n",
    "    \n",
    "    lit_list(\"LOC_Institution\", nvto.isResidenceOf)\n",
    "    uri_type(\"LOC_Institution\", nvto.PerformingArtsGroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in city_clean.iterrows():\n",
    "    \n",
    "    graph = city_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.City)\n",
    "    \n",
    "    lit_list(\"präf_Stadtname\", skos.prefLabel)\n",
    "    lit_list(\"Stadtname_DE\", skos.altLabel)\n",
    "    lit_list(\"Stadtname_EN\", skos.altLabel)\n",
    "    \n",
    "    uri_list(\"Land\", dcterms.isPartOf)\n",
    "    \n",
    "    lit_list(\"LAT\", wgs84_pos.lat)\n",
    "    lit_list(\"LONG\", wgs84_pos.long)\n",
    "    \n",
    "    url_list(\"geonames\", owl.sameAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in country_clean.iterrows():\n",
    "    \n",
    "    graph = country_graph\n",
    "    \n",
    "    uri_type(\"ID\", nvto.Country)\n",
    "    \n",
    "    lit_list(\"präf_Landname\", skos.prefLabel)\n",
    "    lit_list(\"Landname_DE\", skos.altLabel)\n",
    "    lit_list(\"Landname_EN\", skos.altLabel)\n",
    "        \n",
    "    lit_list(\"LAT\", wgs84_pos.lat)\n",
    "    lit_list(\"LONG\", wgs84_pos.long)\n",
    "    \n",
    "    url_list(\"geonames\", owl.sameAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in col_clean.iterrows():\n",
    "    \n",
    "    graph = col_graph    \n",
    "    \n",
    "    uri_type(\"ID\", nvto.Collection)\n",
    "    \n",
    "    lit_list(\"Sammlungstitel\", skos.prefLabel)\n",
    "    lit_list(\"Sammlungstitel\", dcterms.title)\n",
    "        \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in series_clean.iterrows():\n",
    "    \n",
    "    graph = series_graph    \n",
    "    \n",
    "    uri_type(\"ID\", nvto.Series)\n",
    "    \n",
    "    lit_list(\"Serientitel\", skos.prefLabel)\n",
    "    lit_list(\"Serientitel\", dcterms.title)\n",
    "        \n",
    "    lit_list(\"Beschreibung_Quelle\", dcterms.description)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nvt_productions.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(pr_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_events.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(ev_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_videos.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(vid_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_text.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(text_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_img.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(img_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_aud.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(aud_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_person.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(person_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_group.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(group_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_location.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(loc_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_city.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(city_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_country.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(country_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_collection.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(col_graph.serialize(format=\"turtle\"))\n",
    "with open('nvt_series.ttl', 'wb') as f_ttl:\n",
    "    f_ttl.write(series_graph.serialize(format=\"turtle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nvt_ds.trig', 'wb') as f_trig:\n",
    "    f_trig.write(nvt_ds.serialize(format=\"trig\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
