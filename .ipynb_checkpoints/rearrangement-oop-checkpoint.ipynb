{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdflib\n",
    "import numpy as np\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal, RDF, util\n",
    "from rdflib.namespace import NamespaceManager\n",
    "import datetime\n",
    "import pprint\n",
    "pd.options.display.max_colwidth = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = str(datetime.datetime.now().strftime('%Y_%m_%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_columns(sheet, mapping, origin):\n",
    "    ## noch ein bisschen sauberer wäre gut, zeilenumbruch nach beschreibung vllt und personennamen in richtiger schreibweise\n",
    "    ## bei result = texts müssten Autoren noch mit den Labels der Personen, auf die verwiesen wird, versehen werden\n",
    "    \n",
    "    df = sheet.tdf\n",
    "    \n",
    "    if origin == \"zeitraum\":\n",
    "        col1 = mapping[\"zeitraum1\"]\n",
    "        col2 = mapping[\"zeitraum2\"]\n",
    "        col3 = mapping[origin]\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"timespan_\" + df[mapping[\"ID\"]] + \"_\" + df[col1].apply(str).str[:4] + \"_\" + df[col2].apply(str).str[:4]\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"timespan_\" + df[mapping[\"ID\"]] + \"_\" + df[col1].apply(str).str[:4]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \"timespan_\" + df[mapping[\"ID\"]] + \"_\" + df[col2].apply(str).str[:4]\n",
    "    \n",
    "    if origin == \"season\":\n",
    "        col1 = mapping[\"season1\"]\n",
    "        col2 = mapping[\"season2\"]\n",
    "        col3 = mapping[origin]\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"season_\" + df[mapping[\"ID\"]] + \"_\" + df[col1].apply(str).str[:4] + \"_\" + df[col2].apply(str).str[:4]\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"season_\" + df[mapping[\"ID\"]] + \"_\" + df[col1].apply(str).str[:4]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \"season_\" + df[mapping[\"ID\"]] + \"_\" + df[col2].apply(str).str[:4]\n",
    "  \n",
    "    if origin == \"description\":\n",
    "        col1 = mapping[\"description1\"]\n",
    "        col2 = mapping[\"description2\"]\n",
    "        col3 = mapping[origin]\n",
    "        col2_replaced = stringreplace(df[col2], namespace=nvt)\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = df[col1] + \" Quelle: \" + col2_replaced\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = df[col1]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \"Quelle: \" + col2_replaced        \n",
    "    \n",
    "    if origin == \"texts\":\n",
    "        col1 = mapping[\"texts1\"]\n",
    "        col2 = mapping[\"texts2\"]\n",
    "        col3 = mapping[origin]\n",
    "        col2_replaced = stringreplace(df[col2], namespace=nvt)\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"Text(e): \" + df[col1] + \" Autor(en): \" + col2_replaced\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"Text(e): \" + df[col1]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \"Autor(en): \" + col2_replaced\n",
    "        \n",
    "\n",
    "    if origin == \"condition\":\n",
    "        col1 = mapping[\"condition1\"]\n",
    "        col2 = mapping[\"condition2\"]\n",
    "        col3 = mapping[origin]\n",
    "        df.loc[df[col1].notna() & df[col2].notna(), col3] = \"Zustand: \" + df[col1] + \" Datum Zustandsaufnahme: \" + df[col2].apply(str)\n",
    "        df.loc[df[col1].notna() & df[col2].isna(), col3] = \"Zustand: \" + df[col1]\n",
    "        df.loc[df[col1].isna() & df[col2].notna(), col3] = \" Datum Zustandsaufnahme: \" + df[col2].apply(str)       \n",
    "\n",
    "    if origin == \"institution\":\n",
    "        col1 = mapping[\"ID\"]\n",
    "        col2 = mapping[\"institution1\"]\n",
    "        col3 = mapping[origin]\n",
    "        df.loc[df[col2].notna(), col3] = df[col1].str.replace(\"LOC_\", \"G_\")\n",
    "        \n",
    "    if origin == \"physical\": # neue if-Kondition für objekte, die physisch nicht exisitieren\n",
    "        regexr = \"[\\s\\S]+\"\n",
    "        col1 = mapping[\"ID\"]\n",
    "        col3 = mapping[origin]\n",
    "        \n",
    "        if sheet.name == \"Objekte VIDEOS\":\n",
    "            regexr = \"^(vid-[0-9]{3})$\"\n",
    "            df.loc[df[col1].notna() & df[col1].str.match(regexr, na=False), col3] = \"phys_\" + df[col1]\n",
    "            \n",
    "        if sheet.name == \"Objekte BILD\":\n",
    "            regexr = \"(Negativmappe)|(Mappe \\(sonstige\\))|(Fotomappe \\(Positive\\))\"\n",
    "            col2 = \"Archivalientyp\"\n",
    "            df.loc[df[col1].notna() & ~df[col2].str.match(regexr, na=False), col3] = \"phys_\" + df[col1]\n",
    "        \n",
    "        if sheet.name == \"Objekte TEXT\":\n",
    "            regexr = \"(Archivmappe)|(Mappe \\(sonstige\\))|(Typoskript Sammlung)|(Anderes)|(Plakate)\"\n",
    "            col2 = \"Archivalientyp\"\n",
    "            df.loc[df[col1].notna() & ~df[col2].str.match(regexr, na=False), col3] = \"phys_\" + df[col1]\n",
    "            \n",
    "        if sheet.name == \"Objekte AUDIO\":\n",
    "            df[col3] = np.nan\n",
    "        \n",
    "    \n",
    "    if origin == \"type\":\n",
    "        col1 = mapping[origin]\n",
    "        if sheet.name == \"Objekte VIDEOS\":\n",
    "            df[col1] = \"VIDEO\"\n",
    "            \n",
    "        if sheet.name == \"Objekte BILD\":\n",
    "            df[col1] = \"IMAGE\"\n",
    "        \n",
    "        if sheet.name == \"Objekte TEXT\":\n",
    "            df[col1] = \"TEXT\"\n",
    "            \n",
    "        if sheet.name == \"Objekte AUDIO\":\n",
    "            df[col1] = \"SOUND\"\n",
    "        \n",
    "        if sheet.name == \"||_Städte\":\n",
    "            df[col1] = \"stadt\"\n",
    "        \n",
    "        if sheet.name == \"||_Länder\":\n",
    "            df[col1] = \"land\"\n",
    "    \n",
    "    \n",
    "    if origin == \"aggregation\":\n",
    "        col1 = mapping[\"ID\"]\n",
    "        col3 = mapping[origin]\n",
    "        df.loc[df[col1].notna(), col3] = \"agg_\" + df[col1]\n",
    "    \n",
    "    if origin == \"class\":\n",
    "        col1 = mapping[\"class1\"]\n",
    "        col3 = mapping[origin]\n",
    "        pr_types = {\"Produktion (Performing Arts)\":\"paam:PerformingArtsProduction\", \"Film-/Fernsehproduktion\":\"paam:FilmProduction\"}\n",
    "        df[col3] = df[col1].map(pr_types)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_reindex(df, index=None):\n",
    "    df = (df.sort_values(by=[index])\n",
    "          .reset_index(drop=True) ## resets index to be continouus            \n",
    "         )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refreplace(col):\n",
    "    ## string converter for URIs\n",
    "    col = col.str.lower()\n",
    "    col = col.str.replace(\"ä\", \"ae\")\n",
    "    col = col.str.replace(\"ö\",\"oe\")\n",
    "    col = col.str.replace(\"ü\",\"ue\")\n",
    "    col = col.str.replace(\"ß\",\"ss\")\n",
    "    col = col.str.replace(\"!?,\\.\", \"\")\n",
    "    col = col.str.replace(\"[^a-zA-Z0-9;]\", \"_\")\n",
    "    col = col.str.replace(\"-\", \"_\")\n",
    "    col = col.str.replace(\"_{2,}\", \"_\")\n",
    "    col = col.str.strip(\"_\")\n",
    "    col = col.str.strip()\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supersplit(col):\n",
    "    ## for more convenient str splitting within the columns (expand=false), mainly for splitting all URIs\n",
    "    if col.any():\n",
    "        col = col.str.strip()\n",
    "        col = col.str.split(\";\", expand = False)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitreplace(col):\n",
    "    ## combines refreplace and supersplit in correct order for they are both always used for any columns containing URIs\n",
    "    col = refreplace(col)\n",
    "    col = supersplit(col)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringreplace(col, namespace=None):\n",
    "    ## temporary string beautifier for persons as literal values\n",
    "        col = col.str.replace(\"_\",\" \")\n",
    "        col = col.str.replace(\"(?=[A-z]*),(?=[A-z])\", \" \")\n",
    "        col = col.str.replace(\";\", \"; \")\n",
    "        \n",
    "        col = col.str.replace(\"  \", \" \")\n",
    "        \n",
    "        regexr = \"([a-z]{3})(-[0-9]{3}){1,}\"\n",
    "        repl = lambda m: str(namespace) + m.group(0).replace(\"-\",\"_\")\n",
    "        col = col.str.replace(regexr, repl)\n",
    "        \n",
    "        return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_rdf(column, nsm):\n",
    "    newlist = []\n",
    "    for i in column:\n",
    "        if isinstance(i, list):\n",
    "            newlistlist = []\n",
    "            for j in i:\n",
    "                newlistlist.append(util.from_n3(j, nsm=nsm))\n",
    "            newlist.append(newlistlist)\n",
    "        else:\n",
    "            newlist.append(float(\"NaN\"))\n",
    "    column = pd.Series(newlist)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_to_dict(mapping, col_ref):\n",
    "    idx = 0\n",
    "    mapping_list = []\n",
    "    merger = pd.DataFrame\n",
    "    titlekey = pd.DataFrame\n",
    "    for key,value in mapping.items():\n",
    "        \n",
    "\n",
    "\n",
    "        # value.dropna(subset=[\"NVTO Property\"], inplace=True) # droppt alle Spaltennamen Einträge ohne korrespondierende NVTO Property\n",
    "\n",
    "        value[['Subject','Object Class','NVTO Property']] = value[['Subject','Object Class','NVTO Property']].apply(supersplit, axis=1) # splittet alle Spalten mit RDF-Properties oder Classes\n",
    "\n",
    "        value[\"Object Class\"] = str_to_rdf(value[\"Object Class\"], nsm) # wandelt die Werte der Spalte in rdflib URIRefs um\n",
    "\n",
    "        value[\"NVTO Property\"] = str_to_rdf(value[\"NVTO Property\"], nsm) # wandelt die Werte der Spalte in rdflib URIRefs um\n",
    "\n",
    "\n",
    "        merge = (value[['Spaltenname in Tabelle','Merge']].dropna(subset=[\"Merge\"])\n",
    "                                                        .set_index('Merge').T.to_dict('records')) # merge baut dict zum Mergen von \n",
    "\n",
    "        titledict = value.set_index('Spaltenname in Tabelle').T.to_dict('list')\n",
    "        \n",
    "        \n",
    "        clean_titledict = {k:v for (k,v) in titledict.items() if ((isinstance(v[3], list) and k in list(col_ref[key].tdf.columns) \n",
    "                                                                   and v[3]) \n",
    "                                                                  or isinstance(v[0], str))}\n",
    "        \n",
    "        sheetid = value.loc[value['Merge']==\"ID\", 'Spaltenname in Tabelle'].iloc[0]\n",
    "        mapping_list.append(Mapping(sheet = key, #baut Klassenobjekte mit den unten genannten Einträgen\n",
    "                                    df = value, \n",
    "                                    title = value[\"Spaltenname in Tabelle\"], \n",
    "                                    rdfp = value[\"NVTO Property\"],\n",
    "                                    original = value[\"Merge\"],\n",
    "                                    subj = value[\"Subject\"],\n",
    "                                    objclass = value[\"Object Class\"],\n",
    "                                    objtype = value[\"Object Type\"],\n",
    "                                    merge = merge,\n",
    "                                    titledict = titledict,\n",
    "                                    clean_titledict = clean_titledict,\n",
    "                                    sheetid = sheetid\n",
    "                                    )\n",
    "                           )\n",
    "    return mapping_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_transform(col_ref):\n",
    "    \n",
    "    #bei Produktionen sollte am Ende nach 'XX_' gesucht werden, nicht nach PR, und der Typ bei Produktionen wird dann durch die Typenspalte bestimmt\n",
    "    tdf = col_ref[\"Produktionen\"].tdf\n",
    "    tdf = (tdf[tdf['Identifier / geeinigter Name'].str.contains('PR', na=False)] ## drops all rows that don't start with 'PR' or are NaN\n",
    "              .drop(tdf[tdf['Identifier / geeinigter Name'].str.contains('PR_Internationaler_Workshop_zur_Biomechanik_GITIS Moskau_Januar_1993', na=False)].index)\n",
    "           )\n",
    "    col_ref[\"Produktionen\"].tdf = tdf\n",
    "\n",
    "    tdf = col_ref[\"Ereignisse\"].tdf\n",
    "    tdf = (tdf[tdf['Identifier / geeinigter Name'].str.contains('EV', na=False)] ## drops all rows that don't start with 'PR' or are NaN\n",
    "              .drop(tdf[tdf['Identifier / geeinigter Name'].str.contains('EV_Internationaler_Workshop_zur_Biomechanik_GITIS Moskau_Januar_1993_001', na=False)].index) ## drops example line\n",
    "          )\n",
    "    col_ref[\"Ereignisse\"].tdf = tdf\n",
    "\n",
    "    tdf = col_ref[\"Objekte VIDEOS\"].tdf\n",
    "    tdf = tdf[tdf['Projekt ID'].str.contains('vid', na=False)]\n",
    "    col_ref[\"Objekte VIDEOS\"].tdf = tdf\n",
    "\n",
    "    tdf = col_ref[\"Objekte TEXT\"].tdf\n",
    "    tdf = tdf[tdf['Projekt ID'].str.contains('txt', na=False)]\n",
    "    col_ref[\"Objekte TEXT\"].tdf = tdf\n",
    "\n",
    "    tdf = col_ref[\"Objekte BILD\"].tdf\n",
    "    tdf = tdf[tdf['Projekt ID'].str.contains('img', na=False)]\n",
    "    col_ref[\"Objekte BILD\"].tdf = tdf\n",
    "\n",
    "    tdf = col_ref[\"Objekte AUDIO\"].tdf\n",
    "    tdf = tdf[tdf['Projekt ID'].str.contains('aud', na=False)]\n",
    "    col_ref[\"Objekte AUDIO\"].tdf = tdf\n",
    "\n",
    "    tdf = col_ref[\"||_Personen\"].tdf\n",
    "    tdf = (tdf.drop(tdf[tdf['Identifier / geeinigte Schreibweise'].str.contains('Vorname Vatersname,Nachname', na=False)].index)\n",
    "              .drop(tdf[tdf['Identifier / geeinigte Schreibweise'].str.contains('Referenz', na=False)].index)\n",
    "              .drop(tdf[tdf['Identifier / geeinigte Schreibweise'].str.contains('Identifier / geeinigte Schreibweise', na=False)].index)\n",
    "          )\n",
    "    col_ref[\"||_Personen\"].tdf = tdf\n",
    "\n",
    "    tdf = col_ref[\"||_Gruppen_Ensembles\"].tdf\n",
    "    tdf = tdf[tdf['Gruppe Identifier / geeinigte Schreibweise'].str.contains('G_', na=False)]\n",
    "    col_ref[\"||_Gruppen_Ensembles\"].tdf = tdf\n",
    "\n",
    "    tdf = col_ref[\"||_Veranstaltungsort\"].tdf\n",
    "    tdf = tdf[tdf['PROJEKT'].str.contains('LOC_', na=False)]\n",
    "    col_ref[\"||_Veranstaltungsort\"].tdf = tdf\n",
    "\n",
    "    tdf = col_ref[\"Sammlungen\"].tdf\n",
    "    tdf = (tdf[tdf['PROJEKT'].str.contains('COL_', na=False)]\n",
    "              .drop(tdf[tdf['PROJEKT'].str.contains('COL_Identifier', na=False)].index)\n",
    "          )\n",
    "    col_ref[\"Sammlungen\"].tdf = tdf\n",
    "\n",
    "    tdf = col_ref[\"Serie\"].tdf      \n",
    "    tdf = (tdf[tdf['PROJEKT'].str.contains('SRS_', na=False)]\n",
    "               .drop(tdf[tdf['PROJEKT'].str.contains('SRS_Identifier', na=False)].index)\n",
    "           )\n",
    "    col_ref[\"Serie\"].tdf = tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_merge_splitreplace(sheets, mapping):\n",
    "        \n",
    "    # sortiert und reindexiert alle sheetssheets\n",
    "    \n",
    "    for sdx, sheet in enumerate(sheets):\n",
    "            \n",
    "        sheet.tdf = sort_reindex(sheet.tdf, index=mapping[sdx].sheetid)\n",
    "\n",
    "    # für alle Spalten in allen Sheets wird merge_columns angewandt\n",
    "    # mapping[sdx].title = alle Spalten\n",
    "    # mapping[sdx].merge[0] = ID des Sheets, 0, weil Dict seltsam in Liste\n",
    "    # mapping[sdx].original[cdx] = für die Keywords in merge_columns, könnte man vllt auch mit merge[0] machen\n",
    "\n",
    "    for sdx, sheet in enumerate(sheets):\n",
    "        for cdx, column in enumerate(mapping[sdx].title):\n",
    "            merge_columns(sheet, mapping[sdx].merge[0], mapping[sdx].original[cdx]) # für die zusammengesetzten Spalten für z.B. Spielzeit Beschreibung Texte\n",
    "\n",
    "    # Schleife muss getrennt von der oberen laufen, weil in der unteren Listen erzeugt werden, die nicht mehr für die oberen verwendbar sind\n",
    "    # mapping[sdx].title = alle Spalten\n",
    "    # mapping[sdx].titledict[column][5] verbindet Spalte mit Keyword \"Reference\"\n",
    "    # splitreplace wandelt alle Reference Zeilen zu Listen mit Referenzen um\n",
    "    # len(sheets[sdx].tdf[column].value_counts()) > 0 prüft die \n",
    "    for sdx, sheet in enumerate(sheets):\n",
    "        for cdx, column in enumerate(mapping[sdx].title):\n",
    "            reference = mapping[sdx].titledict[column][5]\n",
    "            if (reference == \"Reference\" or reference == \"Inverse\") and len(sheets[sdx].tdf[column].value_counts()) > 0:\n",
    "                sheets[sdx].tdf[column] = splitreplace(sheets[sdx].tdf[column])\n",
    "            if (reference == \"Link\" or reference == \"Type\") and len(sheets[sdx].tdf[column].value_counts()) > 0:\n",
    "                sheets[sdx].tdf[column] = supersplit(sheets[sdx].tdf[column])\n",
    "    \n",
    "    return sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sheets_to_graph(sheet_list, mapping_list):\n",
    "        \n",
    "    missing_columns = []\n",
    "    for sdx, sheet in enumerate(sheet_list):\n",
    "   #     if sdx <= 2:\n",
    "\n",
    "            tdf = sheet.tdf\n",
    "            mapping = mapping_list[sdx]\n",
    "            graph = sheet.graph\n",
    "\n",
    "            # Iteration durch die Zeilen eines Sheets, row ist eine ganze Zeile \n",
    "            for rdx, row in tdf.iterrows():\n",
    " \n",
    "                # pro Spalte pro Zeile, column ist der Wert einer Spalte pro Zeile\n",
    "                for cdx, column in enumerate(row):\n",
    "                    if tdf.columns[cdx] in list(mapping.title): # hier wird verhindert, dass die Mapping Datei alle Titel haben muss, nicht genannte Titel werden allerdings ignoriert\n",
    "                        #Setup der Variablen\n",
    "                        rdfsubj = mapping.titledict[tdf.columns[cdx]][1]\n",
    "                        objclass = mapping.titledict[tdf.columns[cdx]][2]\n",
    "                        rdfprop = mapping.titledict[tdf.columns[cdx]][3]\n",
    "                        objtype = mapping.titledict[tdf.columns[cdx]][5]\n",
    "                    elif tdf.columns[cdx] not in missing_columns:\n",
    "                        missing_columns.append(tdf.columns[cdx])\n",
    "                        \n",
    "                    # alle rdfproperties sind in Listen gespeichert, wenn nicht Liste dann NaN\n",
    "                    if tdf.columns[cdx] in list(mapping.title) and isinstance(rdfprop, list): \n",
    "\n",
    "                        # pro Property der Spalte\n",
    "                        for pdx, prop in enumerate(rdfprop): \n",
    "\n",
    "                            # nur wenn ein anderes Subjekt in Meta_Py angegeben wird, wird idid angepasst\n",
    "                            if isinstance(rdfsubj, list) and (isinstance(column, str) or isinstance(column, list)):\n",
    "                                idid = []\n",
    "                                for irdfsubj in rdfsubj:\n",
    "                                    if isinstance(tdf[irdfsubj][rdx], list): # spalteninhalt der spalte mit namen irdfsubj an stelle rdx\n",
    "                                        if mapping.titledict[irdfsubj][5] == \"Link\":\n",
    "                                            idid.append(URIRef(tdf[irdfsubj][rdx][0]))\n",
    "                                        else:\n",
    "                                            idid.append(nvt[tdf[irdfsubj][rdx][0]])\n",
    "                            else:\n",
    "                                idid = []\n",
    "                                idid.append(nvt[tdf[mapping.sheetid][rdx][0]])\n",
    "\n",
    "                            #str sind nicht als Liste gespeichert, objtype könnte man noch erweitern auf liste von Länderbezeichungen und Datentypen\n",
    "                            if isinstance(column, str) and idid:\n",
    "                                if objtype == \"de\" or objtype == \"en\":\n",
    "                                    language = objtype\n",
    "                                else:\n",
    "                                    language = None\n",
    "                                for i_idid in idid:\n",
    "                                    graph.add((i_idid, prop, Literal(column, lang=language)))\n",
    "\n",
    "                            if isinstance(column, list) and idid: # References sind als Listen gespeichert\n",
    "                                for rdfobj in column:\n",
    "                                    if objtype == \"Reference\" or objtype ==\"Inverse\": #geht grad nur wenn inverse nicht an einem Link hängt\n",
    "                                        new_rdfobj = nvt[rdfobj]\n",
    "                                    elif objtype == \"Link\":\n",
    "                                        new_rdfobj = URIRef(rdfobj)\n",
    "                                    elif objtype == \"Type\":\n",
    "                                        new_rdfobj = util.from_n3(rdfobj, nsm=nsm)\n",
    "                                    \n",
    "                                    for i_idid in idid:\n",
    "                                        if i_idid != new_rdfobj:\n",
    "                                        \n",
    "                                            if objtype == \"Inverse\":\n",
    "                                                graph.add((new_rdfobj, prop, i_idid))\n",
    "\n",
    "                                            elif objtype ==\"Reference\": # hier wird die ID Spalte ausgeschlossen\n",
    "                                                graph.add((i_idid, prop, new_rdfobj))\n",
    "\n",
    "                                            elif objtype ==\"Link\":\n",
    "                                                graph.add((i_idid, prop, new_rdfobj))\n",
    "\n",
    "                                            elif objtype ==\"Type\":\n",
    "                                                graph.add((i_idid, prop, new_rdfobj))\n",
    "                                            \n",
    "\n",
    "                                        if isinstance(objclass, list):\n",
    "                                            for iobjclass in objclass:\n",
    "                                                graph.add((new_rdfobj, rdf.type, iobjclass)) # hier können bei mehreren Subjekten Duplikate entstehen, sollte egal sein\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ALT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sheets_to_graph2(sheet_list, mapping_list):\n",
    "    \n",
    "    missing_columns = []\n",
    "    for sdx, sheet in enumerate(sheet_list):\n",
    "   #     if sdx <= 2:\n",
    "\n",
    "            tdf = sheet.tdf\n",
    "            mapping = mapping_list[sdx]\n",
    "            graph = sheet.graph\n",
    "\n",
    "            # Iteration durch die Zeilen eines Sheets, row ist eine ganze Zeile \n",
    "            for rdx, row in tdf.iterrows():\n",
    " \n",
    "                # pro Spalte pro Zeile, column ist der Wert einer Spalte pro Zeile\n",
    "                for cdx, column in enumerate(row):\n",
    "                    if tdf.columns[cdx] in list(mapping.title): # hier wird verhindert, dass die Mapping Datei alle Titel haben muss, nicht genannte Titel werden allerdings ignoriert\n",
    "                        #Setup der Variablen\n",
    "                        rdfsubj = mapping.titledict[tdf.columns[cdx]][1]\n",
    "                        objclass = mapping.titledict[tdf.columns[cdx]][2]\n",
    "                        rdfprop = mapping.titledict[tdf.columns[cdx]][3]\n",
    "                        objtype = mapping.titledict[tdf.columns[cdx]][5]\n",
    "                    elif tdf.columns[cdx] not in missing_columns:\n",
    "                        missing_columns.append(tdf.columns[cdx])\n",
    "                        \n",
    "                    # alle rdfproperties sind in Listen gespeichert, wenn nicht Liste dann NaN\n",
    "                    if tdf.columns[cdx] in list(mapping.title) and isinstance(rdfprop, list): \n",
    "\n",
    "                        # pro Property der Spalte\n",
    "                        for pdx, prop in enumerate(rdfprop): \n",
    "\n",
    "                            # nur wenn ein anderes Subjekt in Meta_Py angegeben wird, wird idid angepasst\n",
    "                            if isinstance(rdfsubj, list) and (isinstance(column, str) or isinstance(column, list)):\n",
    "                                idid = []\n",
    "                                for irdfsubj in rdfsubj:\n",
    "                                    if isinstance(tdf[irdfsubj][rdx], list): # spalteninhalt der spalte mit namen irdfsubj an stelle rdx\n",
    "                                        idid.append(tdf[irdfsubj][rdx][0])\n",
    "                            else:\n",
    "                                idid = tdf[mapping.sheetid][rdx]\n",
    "\n",
    "                            #str sind nicht als Liste gespeichert, objtype könnte man noch erweitern auf liste von Länderbezeichungen und Datentypen\n",
    "                            if isinstance(column, str) and idid:\n",
    "                                if objtype == \"de\" or objtype == \"en\":\n",
    "                                    language = objtype\n",
    "                                else:\n",
    "                                    language = None\n",
    "                                for i_idid in idid:\n",
    "                                    graph.add((nvt[i_idid], prop, Literal(column, lang=language)))\n",
    "\n",
    "                            if isinstance(column, list) and idid: # References sind als Listen gespeichert\n",
    "                                for rdfobj in column:\n",
    "                                    for i_idid in idid:\n",
    "                                        \n",
    "                                        if objtype == \"Inverse\":\n",
    "                                            graph.add((nvt[rdfobj], prop, nvt[i_idid]))\n",
    "                                        \n",
    "                                        elif i_idid != nvt[rdfobj] and objtype ==\"Reference\": # hier wird die ID Spalte ausgeschlossen\n",
    "                                            graph.add((nvt[i_idid], prop, nvt[rdfobj]))\n",
    "                                            \n",
    "                                        elif i_idid != URIRef(rdfobj) and objtype ==\"Link\":\n",
    "                                            graph.add((nvt[i_idid], prop, URIRef(rdfobj)))\n",
    "                                            \n",
    "                                        elif i_idid != util.from_n3(rdfobj, nsm=nsm) and objtype ==\"Type\":\n",
    "                                            graph.add((nvt[i_idid], prop, util.from_n3(rdfobj, nsm=nsm)))\n",
    "                                            \n",
    "\n",
    "                                        if isinstance(objclass, list):\n",
    "                                            for iobjclass in objclass:\n",
    "                                                graph.add((nvt[rdfobj], rdf.type, iobjclass)) # hier können bei mehreren Subjekten Duplikate entstehen, sollte egal sein\n",
    "                    \n",
    "    print(missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bindbind(graph):\n",
    "    graph.bind(\"bibo\", \"http://purl.org/ontology/bibo/\")\n",
    "    graph.bind(\"context\", \"http://lod.iti-germany.de/contexts/\")\n",
    "    graph.bind(\"dc\", \"http://purl.org/dc/elements/1.1/\")\n",
    "    graph.bind(\"dcterms\", \"http://purl.org/dc/terms/\")\n",
    "    graph.bind(\"dm2e\", \"http://onto.dm2e.eu/schemas/dm2e/\")\n",
    "    graph.bind(\"eclap\", \"http://www.eclap.eu/schema/eclap/\")\n",
    "    graph.bind(\"edm\", \"http://www.europeana.eu/schemas/edm/\")\n",
    "    graph.bind(\"foaf\", \"http://xmlns.com/foaf/0.1/\")\n",
    "    graph.bind(\"mtt_a\", \"http://lod.iti-germany.de/schema/mtt_a/\")\n",
    "    graph.bind(\"nvt\", \"https://lod.mediathek-tanz-theater.de/resource/nvt/\")\n",
    "    graph.bind(\"nvto\", \"http://lod.iti-germany.de/schema/nvto/\")\n",
    "    graph.bind(\"owl\", \"http://www.w3.org/2002/07/owl#\")\n",
    "    graph.bind(\"paam\", \"https://lod.mediathek-tanz-theater.de/schema/paam/\")\n",
    "    graph.bind(\"pro\", \"http://purl.org/spar/pro/\")\n",
    "    graph.bind(\"rdau\", \"http://rdaregistry.info/Elements/u/\")\n",
    "    graph.bind(\"rdf\", \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    graph.bind(\"rdfs\", \"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "    graph.bind(\"skos\", \"http://www.w3.org/2004/02/skos/core#\")\n",
    "    graph.bind(\"wgs84_pos\", \"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "    graph.bind(\"ore\", \"http://www.openarchives.org/ore/terms/\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "context = Namespace(\"http://lod.iti-germany.de/contexts/\")\n",
    "dc = Namespace(\"http://purl.org/dc/elements/1.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "dm2e = Namespace(\"http://onto.dm2e.eu/schemas/dm2e/\")\n",
    "eclap = Namespace(\"http://www.eclap.eu/schema/eclap/\")\n",
    "edm = Namespace(\"http://www.europeana.eu/schemas/edm/\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "mtt_a = Namespace(\"http://lod.iti-germany.de/schema/mtt_a/\")\n",
    "nvt = Namespace(\"https://lod.mediathek-tanz-theater.de/resource/nvt/\")\n",
    "nvto = Namespace(\"http://lod.iti-germany.de/schema/nvto/\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "paam = Namespace(\"https://lod.mediathek-tanz-theater.de/schema/paam/\")\n",
    "pro = Namespace(\"http://purl.org/spar/pro/\")\n",
    "rdau = Namespace(\"http://rdaregistry.info/Elements/u/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "wgs84_pos = Namespace(\"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "ore = Namespace(\"http://www.openarchives.org/ore/terms/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsm = NamespaceManager(Graph())\n",
    "nsm.bind(\"bibo\", \"http://purl.org/ontology/bibo/\")\n",
    "nsm.bind(\"context\", \"http://lod.iti-germany.de/contexts/\")\n",
    "nsm.bind(\"dc\", \"http://purl.org/dc/elements/1.1/\")\n",
    "nsm.bind(\"dcterms\", \"http://purl.org/dc/terms/\")\n",
    "nsm.bind(\"dm2e\", \"http://onto.dm2e.eu/schemas/dm2e/\")\n",
    "nsm.bind(\"eclap\", \"http://www.eclap.eu/schema/eclap/\")\n",
    "nsm.bind(\"edm\", \"http://www.europeana.eu/schemas/edm/\")\n",
    "nsm.bind(\"foaf\", \"http://xmlns.com/foaf/0.1/\")\n",
    "nsm.bind(\"mtt_a\", \"http://lod.iti-germany.de/schema/mtt_a/\")\n",
    "nsm.bind(\"nvt\", \"https://lod.mediathek-tanz-theater.de/resource/nvt/\")\n",
    "nsm.bind(\"nvto\", \"http://lod.iti-germany.de/schema/nvto/\")\n",
    "nsm.bind(\"paam\", \"https://lod.mediathek-tanz-theater.de/schema/paam/\")\n",
    "nsm.bind(\"pro\", \"http://purl.org/spar/pro/\")\n",
    "nsm.bind(\"rdau\", \"http://rdaregistry.info/Elements/u/\")\n",
    "nsm.bind(\"owl\", \"http://www.w3.org/2002/07/owl#\")\n",
    "nsm.bind(\"rdf\", \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "nsm.bind(\"rdfs\", \"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "nsm.bind(\"skos\", \"http://www.w3.org/2004/02/skos/core#\")\n",
    "nsm.bind(\"wgs84_pos\", \"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "nsm.bind(\"ore\", \"http://www.openarchives.org/ore/terms/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvt_ds = rdflib.Dataset()\n",
    "nvt_ds = bindbind(nvt_ds)\n",
    "pr_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/productions\")\n",
    "ev_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/events\")\n",
    "vid_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/videos\")\n",
    "text_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/texts\")\n",
    "img_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/images\")\n",
    "aud_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/audio\")\n",
    "person_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/persons\")\n",
    "group_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/groups\")\n",
    "loc_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/locations\")\n",
    "city_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/cities\")\n",
    "country_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/countries\")\n",
    "col_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/collections\")\n",
    "series_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/series\")\n",
    "concept_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/concepts\")\n",
    "nvto_graph_list = [pr_graph, ev_graph, vid_graph, text_graph, img_graph, aud_graph, person_graph, group_graph, loc_graph, city_graph, country_graph, col_graph, series_graph, concept_graph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=http://lod.iti-germany.de/contexts/paam (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvto_graph = nvt_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/paam\")\n",
    "nvto_graph.parse('C:/Users/Jonas/Dropbox/ITI/NVT_Data-Model/NVTO/nvto.ttl', format='ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "edm_ds = rdflib.Dataset()\n",
    "edm_ds = bindbind(edm_ds)\n",
    "edm_pr_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/productions\")\n",
    "edm_ev_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/events\")\n",
    "edm_vid_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/videos\")\n",
    "edm_text_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/texts\")\n",
    "edm_img_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/images\")\n",
    "edm_aud_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/audio\")\n",
    "edm_person_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/persons\")\n",
    "edm_group_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/groups\")\n",
    "edm_loc_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/locations\")\n",
    "edm_city_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/cities\")\n",
    "edm_country_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/countries\")\n",
    "edm_col_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/collections\")\n",
    "edm_series_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/series\")\n",
    "edm_concept_graph = edm_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/concepts\")\n",
    "edm_graph_list = [edm_pr_graph, edm_ev_graph, edm_vid_graph, edm_text_graph, edm_img_graph, edm_aud_graph, edm_person_graph, edm_group_graph, edm_loc_graph, edm_city_graph, edm_country_graph, edm_col_graph, edm_series_graph, edm_concept_graph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_ds = rdflib.Dataset()\n",
    "fid_ds = bindbind(fid_ds)\n",
    "fid_pr_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/productions\")\n",
    "fid_ev_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/events\")\n",
    "fid_vid_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/videos\")\n",
    "fid_text_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/texts\")\n",
    "fid_img_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/images\")\n",
    "fid_aud_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/audio\")\n",
    "fid_person_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/persons\")\n",
    "fid_group_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/groups\")\n",
    "fid_loc_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/locations\")\n",
    "fid_city_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/cities\")\n",
    "fid_country_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/countries\")\n",
    "fid_col_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/collections\")\n",
    "fid_series_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/series\")\n",
    "fid_concept_graph = fid_ds.graph(identifier=\"http://lod.iti-germany.de/contexts/concepts\")\n",
    "fid_graph_list = [fid_pr_graph, fid_ev_graph, fid_vid_graph, fid_text_graph, fid_img_graph, fid_aud_graph, fid_person_graph, fid_group_graph, fid_loc_graph, fid_city_graph, fid_country_graph, fid_col_graph, fid_series_graph, fid_concept_graph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sheet():\n",
    "## name: Name des Reiters\n",
    "## head: Indikator, wo im df Tabellenüberschriften zu finden sind (0 = Inhalte Zeile 1, 1 = Inhalte Zeile 2, x = Index unverändert)\n",
    "## df: DataFrame pro Sheet\n",
    "## tdf: Kopie von df, mit über head definierter Indexanpassung\n",
    "## tdf_empty_transposed: DataFrame, der nur aus Überschriften (ohne Spaltenachsennamen) besteht, zur Konvertierung nach Excel, inklusive Transponierung\n",
    "    def __init__(self, name, head, df, graph):\n",
    "        self.name = name\n",
    "        self.head = head\n",
    "        self.df = df\n",
    "        self.graph = graph\n",
    "        self.tdf = df.copy()\n",
    "        self.column_names = None\n",
    "        self.tdf_empty_transposed = None\n",
    "        \n",
    "        if self.head != \"x\":\n",
    "            self.tdf.columns = self.tdf.iloc[self.head]\n",
    "            self.tdf.columns.name = None\n",
    "        else:\n",
    "            pass\n",
    "        if isinstance(self.tdf, pd.DataFrame):\n",
    "            self.column_names = self.tdf.columns.tolist()\n",
    "            self.tdf_empty_transposed = self.tdf[0:0].transpose(copy=True)\n",
    "            self.tdf = self.tdf[self.tdf.columns.dropna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapping():\n",
    "    \n",
    "    def __init__(self, sheet, df, title, rdfp, original, subj, objclass, objtype, merge, titledict, clean_titledict, sheetid):\n",
    "        self.sheet = sheet\n",
    "        self.df = df\n",
    "        self.title = title\n",
    "        self.rdfp = rdfp\n",
    "        self.original = original\n",
    "        self.subj = subj\n",
    "        self.objclass = objclass\n",
    "        self.objtype = objtype\n",
    "        self.merge = merge\n",
    "        self.titledict = titledict\n",
    "        self.clean_titledict = clean_titledict\n",
    "        self.sheetid = sheetid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvt_master = pd.read_excel('./NVT_Metadatentabelle_MASTER_21012020.xlsm', sheet_name=None)\n",
    "#nvt_master_old = pd.read_excel('./NVT_Metadatentabelle_MASTER_0609test.xlsm', sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvto_columns_mapped = pd.read_excel('./Mapping_Meta_NVT.xlsx', sheet_name=None)\n",
    "edm_columns_mapped = pd.read_excel('./Mapping_Meta_EDM.xlsx', sheet_name=None)\n",
    "fid_columns_mapped = pd.read_excel('./Mapping_Meta_FID.xlsx', sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#master_val = [i for i in nvt_master.values()]\n",
    "#master_val_old = [i for i in nvt_master_old.values()]\n",
    "#\n",
    "#\n",
    "#for idx, i in enumerate(master_val):\n",
    "#    if any(i != master_val_old[idx]) == True:\n",
    "#        print(\"It is true\")\n",
    "#    if i.equals(master_val_old[idx]):\n",
    "#        print(\"It is not true\")\n",
    "#    if i.columns.equals(master_val_old[idx].columns):\n",
    "#        print(\"heyo\")\n",
    "#    print(master_val_old[idx].columns, \"\\n\", i.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zur Erzeungung von Sheet Instanzen mit Name und Spaltenkopfreferenz als Liste und mit dict Referenz\n",
    "## column_headers: Liste von 'echten' Spaltenüberschriften, 0, 1, für erste, zweite Zeile, x=Standard\n",
    "## col_ref dict um nicht mit Zahlen, sondern Namen zu arbeiten\n",
    "## sheet_dict manuell, falls Verschiebungen in Tabelle passieren\n",
    "fid_sheet_list = []\n",
    "nvto_sheet_list = []\n",
    "edm_sheet_list = []\n",
    "nvto_col_ref = {}\n",
    "edm_col_ref = {}\n",
    "fid_col_ref = {}\n",
    "sheet_dict = {\"Produktionen\":0,\n",
    "             \"Ereignisse\":0,\n",
    "             \"Objekte VIDEOS\":0,\n",
    "             \"Objekte TEXT\":0,\n",
    "             \"Objekte BILD\":0,\n",
    "             \"Objekte AUDIO\":0,\n",
    "             \"||_Personen\":1,\n",
    "             \"||_Gruppen_Ensembles\":\"x\",\n",
    "             \"||_Veranstaltungsort\":\"x\",\n",
    "             \"||_Städte\":\"x\",\n",
    "             \"||_Länder\":\"x\",\n",
    "             \"Sammlungen\":\"x\",\n",
    "             \"Serie\":\"x\"}\n",
    "\n",
    "for idx, i in enumerate(sheet_dict.keys()):\n",
    "    fid_sheet_list.append(Sheet(name = i, head = sheet_dict[i], df = nvt_master[i], graph = fid_graph_list[idx]))\n",
    "    nvto_sheet_list.append(Sheet(name = i, head = sheet_dict[i], df = nvt_master[i], graph = nvto_graph_list[idx]))\n",
    "    edm_sheet_list.append(Sheet(name = i, head = sheet_dict[i], df = nvt_master[i], graph = edm_graph_list[idx]))\n",
    "    nvto_col_ref[i] = nvto_sheet_list[idx]\n",
    "    edm_col_ref[i] = edm_sheet_list[idx]\n",
    "    fid_col_ref[i] = fid_sheet_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer_trigger = False\n",
    "#for idx, sheet in enumerate(sheet_list):\n",
    "#    new_sheet = sheet.tdf\n",
    "#    old_sheet = old_sheet_list[idx].tdf\n",
    "#    if new_sheet.columns.equals(old_sheet.columns) == True:\n",
    "#        print(\"true\")\n",
    "#        pass\n",
    "#    else:\n",
    "#        print(\"it is equals yes it does\")\n",
    "#        print(new_sheet.columns)\n",
    "#        print(old_sheet.columns)\n",
    "#        writer_trigger = True\n",
    "#        break\n",
    "## könnte alle abweichenden columns in neuer file gelb markieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvto_mapping_list = mapping_to_dict(nvto_columns_mapped, nvto_col_ref)\n",
    "nvto_col_ref = initial_transform(nvto_col_ref)\n",
    "nvto_sheet_list = reindex_merge_splitreplace(nvto_sheet_list, nvto_mapping_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_to_graph(nvto_sheet_list, nvto_mapping_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nvt_ds_' + str(time) + '.trig', 'wb') as f_trig:\n",
    "    f_trig.write(nvt_ds.serialize(format=\"trig\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "edm_mapping_list = mapping_to_dict(edm_columns_mapped, edm_col_ref)\n",
    "edm_col_ref = initial_transform(edm_col_ref)\n",
    "edm_sheet_list = reindex_merge_splitreplace(edm_sheet_list, edm_mapping_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_mapping_list = mapping_to_dict(fid_columns_mapped, fid_col_ref)\n",
    "fid_col_ref = initial_transform(fid_col_ref)\n",
    "fid_sheet_list = reindex_merge_splitreplace(fid_sheet_list, fid_mapping_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "sheets_to_graph(edm_sheet_list, edm_mapping_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "sheets_to_graph(fid_sheet_list, fid_mapping_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edm_ds_' + str(time) + '.trig', 'wb') as f_trig:\n",
    "    f_trig.write(edm_ds.serialize(format=\"trig\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fid_ds_' + str(time) + '.trig', 'wb') as f_trig:\n",
    "    f_trig.write(fid_ds.serialize(format=\"trig\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
